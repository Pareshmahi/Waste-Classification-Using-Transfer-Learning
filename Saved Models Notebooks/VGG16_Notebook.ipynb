{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PPH8BVT0Q9b9",
        "outputId": "f16ba3ee-1046-463a-c714-0b633b56d0fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AQcus6fZSR4y",
        "outputId": "f4dc8f2b-3548-473d-b700-7869c72ebe88"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m112.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m84.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m58.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m84.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.14.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch torchvision torchaudio\n",
        "!pip install tqdm matplotlib scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8PujdC_ZSv7J"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import time\n",
        "import os\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision.datasets import ImageFolder\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from tqdm import tqdm\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VB_vXA04TOyn",
        "outputId": "ae722ba5-dd82-4651-dd93-d0d427a66c6f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of GPUs available: 1\n",
            "Current GPU: Tesla T4\n",
            "Device type: cuda\n"
          ]
        }
      ],
      "source": [
        "# Check if CUDA (GPU support) is available\n",
        "if torch.cuda.is_available():\n",
        "    # Get the number of available GPUs\n",
        "    num_gpus = torch.cuda.device_count()\n",
        "    print(f\"Number of GPUs available: {num_gpus}\")\n",
        "\n",
        "    # Get the name of the current GPU\n",
        "    gpu_name = torch.cuda.get_device_name(torch.cuda.current_device())\n",
        "    print(f\"Current GPU: {gpu_name}\")\n",
        "\n",
        "    # Get GPU device properties\n",
        "    device = torch.device('cuda')\n",
        "    print(f\"Device type: {device.type}\")\n",
        "else:\n",
        "    print(\"CUDA is not available. PyTorch will run on the CPU.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3TKp-8q4UN4Y",
        "outputId": "18cad429-c103-4fd3-e2bb-2ee8bce3e752"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classes: ['cardboard', 'e-waste', 'glass', 'medical', 'metal', 'paper', 'plastic']\n",
            "Checking dataset for corrupt images...\n",
            "Corrupt or non-image file found: /content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/paper/paper 2273.jpg\n",
            "Corrupt or non-image file found: /content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/cardboard/cardboard 1075.jpg\n",
            "Corrupt or non-image file found: /content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/e-waste/e-waste 1719.jpg\n",
            "Checking dataset for corrupt images...\n",
            "Dataset loaded successfully!\n"
          ]
        }
      ],
      "source": [
        "# Standard image size for CNNs (Adjust dynamically for Inception-V3)\n",
        "selected_model_name = \"Inception-V3\"  # Change this dynamically if needed\n",
        "image_size = 299 if selected_model_name == \"Inception-V3\" else 224\n",
        "\n",
        "# Custom dataset class to handle corrupt images\n",
        "class CustomImageFolder(ImageFolder):\n",
        "    def __getitem__(self, index):\n",
        "        try:\n",
        "            return super().__getitem__(index)\n",
        "        except Exception as e:\n",
        "            print(f\"Skipping corrupted image: {self.imgs[index][0]} - {e}\")\n",
        "            return torch.zeros(3, image_size, image_size), 0  # Return a blank image\n",
        "\n",
        "# Optimized Transformations (Order adjusted for stability)\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(image_size, scale=(0.8, 1.0)),  # Crop first\n",
        "    transforms.Resize((image_size, image_size)),  # Resize after crop\n",
        "    transforms.Lambda(lambda img: img.convert('RGB')),  # Ensure RGB\n",
        "    transforms.RandomHorizontalFlip(p=0.5),  # Flip 50% of the time\n",
        "    transforms.RandomRotation(10),  # Rotate within ±10 degrees\n",
        "    transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.05),  # Color variation\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])  # Standard normalization\n",
        "])\n",
        "\n",
        "val_transforms = transforms.Compose([\n",
        "    transforms.Resize((image_size, image_size)),\n",
        "    transforms.Lambda(lambda img: img.convert('RGB')),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Paths\n",
        "dataset_path = \"/content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset\"\n",
        "validation_path = \"/content/drive/MyDrive/Waste Classification using Transfer Learning/Data Validation\"\n",
        "\n",
        "# Hyperparameters (Optimized for Performance)\n",
        "batch_size = 32  # Changed from 64 to 32\n",
        "num_workers = 4  # Parallel data loading\n",
        "\n",
        "# Load dataset with corrupt image handling\n",
        "train_dataset = CustomImageFolder(root=dataset_path, transform=train_transforms)\n",
        "val_dataset = CustomImageFolder(root=validation_path, transform=val_transforms)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
        "\n",
        "# Print class names to verify\n",
        "print(\"Classes:\", train_dataset.classes)\n",
        "\n",
        "# Function to check for corrupt images before training\n",
        "def check_corrupt_images(dataset_path):\n",
        "    print(\"Checking dataset for corrupt images...\")\n",
        "    for folder in os.listdir(dataset_path):\n",
        "        folder_path = os.path.join(dataset_path, folder)\n",
        "        if os.path.isdir(folder_path):\n",
        "            for file in os.listdir(folder_path):\n",
        "                file_path = os.path.join(folder_path, file)\n",
        "                try:\n",
        "                    with Image.open(file_path) as img:\n",
        "                        img.verify()  # Verify image integrity\n",
        "                except:\n",
        "                    print(f\"Corrupt or non-image file found: {file_path}\")\n",
        "\n",
        "# Run dataset check\n",
        "check_corrupt_images(dataset_path)\n",
        "check_corrupt_images(validation_path)\n",
        "\n",
        "print(\"Dataset loaded successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qtg9Ou58UVGs"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "def train_model(model, model_name, criterion, optimizer, train_loader, val_loader, device, num_epochs=25, patience=5, scheduler=None):\n",
        "    train_losses, val_losses, train_accs, val_accs = [], [], [], []\n",
        "    best_val_acc = 0  # Track best validation accuracy\n",
        "    best_val_loss = float('inf')  # Track best validation loss\n",
        "    patience_counter = 0\n",
        "\n",
        "    # Create directory for saving models\n",
        "    save_dir = os.path.join(\"/content/drive/MyDrive/Waste Classification using Transfer Learning/Saved Models\", model_name)\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "    print(\"Starting training...\")\n",
        "\n",
        "    for epoch in range(1, num_epochs + 1):\n",
        "        print(f\"\\nEpoch {epoch}/{num_epochs} started...\")\n",
        "        model.train()\n",
        "        running_loss, correct, total = 0.0, 0, 0\n",
        "\n",
        "        for batch_idx, (inputs, labels) in enumerate(train_loader):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            outputs = model(inputs)\n",
        "\n",
        "            # ✅ Fix for Inception-V3: Extract main output if needed\n",
        "            if isinstance(outputs, tuple):\n",
        "                outputs = outputs[0]  # Get only the main output\n",
        "\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "            if batch_idx % 10 == 0:\n",
        "                print(f\"Batch {batch_idx}/{len(train_loader)}: Loss = {loss.item():.4f}\")\n",
        "\n",
        "        train_loss = running_loss / len(train_loader)\n",
        "        train_acc = (correct / total) * 100\n",
        "\n",
        "        print(\"Training phase completed. Starting validation...\")\n",
        "\n",
        "        # Validation Phase\n",
        "        model.eval()\n",
        "        val_loss, val_correct, val_total = 0.0, 0, 0\n",
        "        all_preds, all_labels = [], []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch_idx, (inputs, labels) in enumerate(val_loader):\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                outputs = model(inputs)\n",
        "\n",
        "                # ✅ Fix for Inception-V3: Extract main output if needed\n",
        "                if isinstance(outputs, tuple):\n",
        "                    outputs = outputs[0]\n",
        "\n",
        "                loss = criterion(outputs, labels)\n",
        "                val_loss += loss.item()\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "                val_total += labels.size(0)\n",
        "                val_correct += (predicted == labels).sum().item()\n",
        "\n",
        "                all_preds.extend(predicted.cpu().numpy())\n",
        "                all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "        val_loss /= len(val_loader)\n",
        "        val_acc = (val_correct / val_total) * 100\n",
        "\n",
        "        # Compute Precision, Recall, and F1-score\n",
        "        precision = precision_score(all_labels, all_preds, average='macro') * 100\n",
        "        recall = recall_score(all_labels, all_preds, average='macro') * 100\n",
        "        f1 = f1_score(all_labels, all_preds, average='macro') * 100\n",
        "\n",
        "        # Store metrics\n",
        "        train_losses.append(train_loss)\n",
        "        val_losses.append(val_loss)\n",
        "        train_accs.append(train_acc)\n",
        "        val_accs.append(val_acc)\n",
        "\n",
        "        # Print Metrics for Each Epoch\n",
        "        print(f\"Epoch [{epoch}/{num_epochs}] completed.\")\n",
        "        print(f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}%\")\n",
        "        print(f\"Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.2f}%\")\n",
        "        print(f\"Precision: {precision:.2f}% | Recall: {recall:.2f}% | F1-score: {f1:.2f}%\")\n",
        "\n",
        "        # Save checkpoint every 5 epochs\n",
        "        if epoch % 5 == 0:\n",
        "            checkpoint_path = os.path.join(save_dir, f'checkpoint_epoch_{epoch}.pth')\n",
        "            checkpoint = {\n",
        "                'epoch': epoch,\n",
        "                'model_state_dict': model.state_dict(),\n",
        "                'optimizer_state_dict': optimizer.state_dict(),\n",
        "                'train_loss': train_loss,\n",
        "                'val_loss': val_loss,\n",
        "                'val_acc': val_acc\n",
        "            }\n",
        "            torch.save(checkpoint, checkpoint_path)\n",
        "            print(f\"Checkpoint saved at {checkpoint_path}!\")\n",
        "\n",
        "        # Save best model (based on validation accuracy or loss)\n",
        "        if val_loss < best_val_loss or val_acc > best_val_acc:\n",
        "            best_val_loss = min(best_val_loss, val_loss)\n",
        "            best_val_acc = max(best_val_acc, val_acc)\n",
        "            patience_counter = 0  # Reset patience counter\n",
        "\n",
        "            best_model_path = os.path.join(save_dir, 'Model_VGG16.pth')\n",
        "            torch.save({\n",
        "                'epoch': epoch,\n",
        "                'model_state_dict': model.state_dict(),\n",
        "                'optimizer_state_dict': optimizer.state_dict(),\n",
        "                'train_loss': train_loss,\n",
        "                'val_loss': val_loss,\n",
        "                'val_acc': val_acc\n",
        "            }, best_model_path)\n",
        "\n",
        "            print(f\"New best model saved at {best_model_path}!\")\n",
        "        else:\n",
        "            patience_counter += 1  # Increment counter if no improvement\n",
        "\n",
        "        # Early Stopping Condition\n",
        "        if patience_counter >= patience:\n",
        "            print(f\"Early stopping at epoch {epoch} due to no improvement in validation loss or accuracy.\")\n",
        "            break\n",
        "\n",
        "    print(\"Training complete!\")\n",
        "    return train_losses, val_losses, train_accs, val_accs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZBiHdRnAVDlU",
        "outputId": "5c01d86c-d1f8-44b3-b7ec-61d8255e0e10"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
            "100%|██████████| 97.8M/97.8M [00:00<00:00, 109MB/s]\n",
            "Downloading: \"https://download.pytorch.org/models/resnet34-b627a593.pth\" to /root/.cache/torch/hub/checkpoints/resnet34-b627a593.pth\n",
            "100%|██████████| 83.3M/83.3M [00:00<00:00, 97.1MB/s]\n",
            "Downloading: \"https://download.pytorch.org/models/efficientnet_b0_rwightman-7f5810bc.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b0_rwightman-7f5810bc.pth\n",
            "100%|██████████| 20.5M/20.5M [00:00<00:00, 101MB/s]\n",
            "Downloading: \"https://download.pytorch.org/models/efficientnet_b3_rwightman-b3899882.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b3_rwightman-b3899882.pth\n",
            "100%|██████████| 47.2M/47.2M [00:00<00:00, 92.5MB/s]\n",
            "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n",
            "100%|██████████| 528M/528M [00:03<00:00, 142MB/s]\n",
            "Downloading: \"https://download.pytorch.org/models/densenet121-a639ec97.pth\" to /root/.cache/torch/hub/checkpoints/densenet121-a639ec97.pth\n",
            "100%|██████████| 30.8M/30.8M [00:00<00:00, 158MB/s]\n",
            "Downloading: \"https://download.pytorch.org/models/mobilenet_v2-b0353104.pth\" to /root/.cache/torch/hub/checkpoints/mobilenet_v2-b0353104.pth\n",
            "100%|██████████| 13.6M/13.6M [00:00<00:00, 143MB/s]\n",
            "Downloading: \"https://download.pytorch.org/models/inception_v3_google-0cc3c7bd.pth\" to /root/.cache/torch/hub/checkpoints/inception_v3_google-0cc3c7bd.pth\n",
            "100%|██████████| 104M/104M [00:00<00:00, 162MB/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training VGG16...\n",
            "\n",
            "Starting training...\n",
            "\n",
            "Epoch 1/25 started...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 0/455: Loss = 2.0896\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 10/455: Loss = 1.3171\n",
            "Batch 20/455: Loss = 1.3391\n",
            "Batch 30/455: Loss = 0.8815\n",
            "Batch 40/455: Loss = 0.9332\n",
            "Batch 50/455: Loss = 1.0431\n",
            "Batch 60/455: Loss = 1.1301\n",
            "Batch 70/455: Loss = 0.7138\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 80/455: Loss = 0.8757\n",
            "Batch 90/455: Loss = 0.7689\n",
            "Batch 100/455: Loss = 1.0338\n",
            "Batch 110/455: Loss = 0.7926\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 120/455: Loss = 0.7091\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 130/455: Loss = 0.5276\n",
            "Batch 140/455: Loss = 0.6515\n",
            "Batch 150/455: Loss = 0.6821\n",
            "Batch 160/455: Loss = 0.6931\n",
            "Skipping corrupted image: /content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/cardboard/cardboard 1075.jpg - cannot identify image file <_io.BufferedReader name='/content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/cardboard/cardboard 1075.jpg'>\n",
            "Batch 170/455: Loss = 1.0616\n",
            "Batch 180/455: Loss = 1.0505\n",
            "Skipping corrupted image: /content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/e-waste/e-waste 1719.jpg - cannot identify image file <_io.BufferedReader name='/content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/e-waste/e-waste 1719.jpg'>\n",
            "Batch 190/455: Loss = 0.8415\n",
            "Batch 200/455: Loss = 0.8357\n",
            "Batch 210/455: Loss = 0.8470\n",
            "Batch 220/455: Loss = 0.5776\n",
            "Batch 230/455: Loss = 0.5849\n",
            "Batch 240/455: Loss = 0.9257\n",
            "Batch 250/455: Loss = 0.4948\n",
            "Batch 260/455: Loss = 0.7818\n",
            "Batch 270/455: Loss = 0.9000\n",
            "Batch 280/455: Loss = 0.6538\n",
            "Batch 290/455: Loss = 0.5505\n",
            "Batch 300/455: Loss = 0.4447\n",
            "Batch 310/455: Loss = 0.6042\n",
            "Batch 320/455: Loss = 0.4413\n",
            "Batch 330/455: Loss = 0.6396\n",
            "Batch 340/455: Loss = 0.5530\n",
            "Batch 350/455: Loss = 0.6541\n",
            "Batch 360/455: Loss = 0.5946\n",
            "Batch 370/455: Loss = 0.6250\n",
            "Skipping corrupted image: /content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/paper/paper 2273.jpg - cannot identify image file <_io.BufferedReader name='/content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/paper/paper 2273.jpg'>\n",
            "Batch 380/455: Loss = 0.7907\n",
            "Batch 390/455: Loss = 0.7546\n",
            "Batch 400/455: Loss = 0.3867\n",
            "Batch 410/455: Loss = 0.7987\n",
            "Batch 420/455: Loss = 0.6184\n",
            "Batch 430/455: Loss = 0.7296\n",
            "Batch 440/455: Loss = 0.4810\n",
            "Batch 450/455: Loss = 0.6180\n",
            "Training phase completed. Starting validation...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/25] completed.\n",
            "Train Loss: 0.7950 | Train Acc: 72.87%\n",
            "Val Loss: 0.5386 | Val Acc: 82.32%\n",
            "Precision: 83.40% | Recall: 81.65% | F1-score: 82.03%\n",
            "New best model saved at /content/drive/MyDrive/Waste Classification using Transfer Learning/Saved Models/VGG16/Model_VGG16.pth!\n",
            "\n",
            "Epoch 2/25 started...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 0/455: Loss = 0.4793\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 10/455: Loss = 0.3579\n",
            "Batch 20/455: Loss = 0.3284\n",
            "Batch 30/455: Loss = 0.6762\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 40/455: Loss = 0.5475\n",
            "Skipping corrupted image: /content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/e-waste/e-waste 1719.jpg - cannot identify image file <_io.BufferedReader name='/content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/e-waste/e-waste 1719.jpg'>\n",
            "Skipping corrupted image: /content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/paper/paper 2273.jpg - cannot identify image file <_io.BufferedReader name='/content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/paper/paper 2273.jpg'>\n",
            "Batch 50/455: Loss = 0.3336\n",
            "Batch 60/455: Loss = 0.8595\n",
            "Batch 70/455: Loss = 0.3560\n",
            "Batch 80/455: Loss = 0.4765\n",
            "Batch 90/455: Loss = 0.4479\n",
            "Batch 100/455: Loss = 0.5135\n",
            "Batch 110/455: Loss = 0.2377\n",
            "Batch 120/455: Loss = 0.4337\n",
            "Batch 130/455: Loss = 0.5612\n",
            "Batch 140/455: Loss = 0.3980\n",
            "Batch 150/455: Loss = 0.7824\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 160/455: Loss = 0.5423\n",
            "Batch 170/455: Loss = 0.6427\n",
            "Batch 180/455: Loss = 0.3159\n",
            "Batch 190/455: Loss = 0.3386\n",
            "Batch 200/455: Loss = 0.1161\n",
            "Batch 210/455: Loss = 0.5219\n",
            "Batch 220/455: Loss = 0.4786\n",
            "Batch 230/455: Loss = 0.3537\n",
            "Batch 240/455: Loss = 0.7076\n",
            "Batch 250/455: Loss = 0.3495\n",
            "Batch 260/455: Loss = 0.4126\n",
            "Batch 270/455: Loss = 0.3064\n",
            "Batch 280/455: Loss = 0.2954\n",
            "Batch 290/455: Loss = 0.5147\n",
            "Batch 300/455: Loss = 0.2065\n",
            "Batch 310/455: Loss = 0.5370\n",
            "Batch 320/455: Loss = 0.3023\n",
            "Batch 330/455: Loss = 0.2521\n",
            "Batch 340/455: Loss = 0.5701\n",
            "Batch 350/455: Loss = 0.3873\n",
            "Batch 360/455: Loss = 1.0794\n",
            "Batch 370/455: Loss = 0.3023\n",
            "Skipping corrupted image: /content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/cardboard/cardboard 1075.jpg - cannot identify image file <_io.BufferedReader name='/content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/cardboard/cardboard 1075.jpg'>\n",
            "Batch 380/455: Loss = 0.3605\n",
            "Batch 390/455: Loss = 0.4420\n",
            "Batch 400/455: Loss = 0.4363\n",
            "Batch 410/455: Loss = 0.8755\n",
            "Batch 420/455: Loss = 0.2972\n",
            "Batch 430/455: Loss = 0.4530\n",
            "Batch 440/455: Loss = 0.2999\n",
            "Batch 450/455: Loss = 0.4311\n",
            "Training phase completed. Starting validation...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [2/25] completed.\n",
            "Train Loss: 0.4889 | Train Acc: 83.35%\n",
            "Val Loss: 0.4757 | Val Acc: 84.72%\n",
            "Precision: 85.56% | Recall: 83.58% | F1-score: 84.10%\n",
            "New best model saved at /content/drive/MyDrive/Waste Classification using Transfer Learning/Saved Models/VGG16/Model_VGG16.pth!\n",
            "\n",
            "Epoch 3/25 started...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 0/455: Loss = 0.4454\n",
            "Batch 10/455: Loss = 0.4087\n",
            "Batch 20/455: Loss = 0.3485\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 30/455: Loss = 0.4228\n",
            "Batch 40/455: Loss = 0.3525\n",
            "Batch 50/455: Loss = 0.5130\n",
            "Batch 60/455: Loss = 0.5283\n",
            "Batch 70/455: Loss = 0.2518\n",
            "Batch 80/455: Loss = 0.2831\n",
            "Batch 90/455: Loss = 0.3113\n",
            "Batch 100/455: Loss = 0.3178\n",
            "Batch 110/455: Loss = 0.9504\n",
            "Batch 120/455: Loss = 0.3577\n",
            "Batch 130/455: Loss = 0.2962\n",
            "Batch 140/455: Loss = 0.4865\n",
            "Batch 150/455: Loss = 0.4143\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 160/455: Loss = 0.4441\n",
            "Batch 170/455: Loss = 0.5094\n",
            "Batch 180/455: Loss = 0.2512\n",
            "Batch 190/455: Loss = 0.3264\n",
            "Batch 200/455: Loss = 0.4815\n",
            "Batch 210/455: Loss = 0.2208\n",
            "Batch 220/455: Loss = 0.5441\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 230/455: Loss = 0.1351\n",
            "Batch 240/455: Loss = 0.2848\n",
            "Batch 250/455: Loss = 0.1139\n",
            "Batch 260/455: Loss = 0.5215\n",
            "Batch 270/455: Loss = 0.1613\n",
            "Batch 280/455: Loss = 0.2226\n",
            "Skipping corrupted image: /content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/e-waste/e-waste 1719.jpg - cannot identify image file <_io.BufferedReader name='/content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/e-waste/e-waste 1719.jpg'>\n",
            "Skipping corrupted image: /content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/paper/paper 2273.jpg - cannot identify image file <_io.BufferedReader name='/content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/paper/paper 2273.jpg'>\n",
            "Batch 290/455: Loss = 0.2329\n",
            "Batch 300/455: Loss = 0.2876\n",
            "Batch 310/455: Loss = 0.4001\n",
            "Batch 320/455: Loss = 0.1185\n",
            "Batch 330/455: Loss = 0.4518\n",
            "Batch 340/455: Loss = 0.4499\n",
            "Batch 350/455: Loss = 0.5005\n",
            "Batch 360/455: Loss = 0.3192\n",
            "Batch 370/455: Loss = 0.4686\n",
            "Batch 380/455: Loss = 0.5766\n",
            "Skipping corrupted image: /content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/cardboard/cardboard 1075.jpg - cannot identify image file <_io.BufferedReader name='/content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/cardboard/cardboard 1075.jpg'>\n",
            "Batch 390/455: Loss = 0.1911\n",
            "Batch 400/455: Loss = 0.2237\n",
            "Batch 410/455: Loss = 0.5665\n",
            "Batch 420/455: Loss = 0.3184\n",
            "Batch 430/455: Loss = 0.1531\n",
            "Batch 440/455: Loss = 0.3730\n",
            "Batch 450/455: Loss = 0.1675\n",
            "Training phase completed. Starting validation...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [3/25] completed.\n",
            "Train Loss: 0.3768 | Train Acc: 87.45%\n",
            "Val Loss: 0.5245 | Val Acc: 83.61%\n",
            "Precision: 84.14% | Recall: 83.81% | F1-score: 83.44%\n",
            "\n",
            "Epoch 4/25 started...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 0/455: Loss = 0.4711\n",
            "Batch 10/455: Loss = 0.3531\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 20/455: Loss = 0.4243\n",
            "Batch 30/455: Loss = 0.1233\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 40/455: Loss = 0.2776\n",
            "Batch 50/455: Loss = 0.3808\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 60/455: Loss = 0.3396\n",
            "Batch 70/455: Loss = 0.2688\n",
            "Batch 80/455: Loss = 0.1218\n",
            "Batch 90/455: Loss = 0.4033\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 100/455: Loss = 0.2292\n",
            "Batch 110/455: Loss = 0.1562\n",
            "Batch 120/455: Loss = 0.3113\n",
            "Batch 130/455: Loss = 0.1742\n",
            "Skipping corrupted image: /content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/e-waste/e-waste 1719.jpg - cannot identify image file <_io.BufferedReader name='/content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/e-waste/e-waste 1719.jpg'>\n",
            "Batch 140/455: Loss = 0.1049\n",
            "Batch 150/455: Loss = 0.2125\n",
            "Batch 160/455: Loss = 0.3660\n",
            "Batch 170/455: Loss = 0.2114\n",
            "Batch 180/455: Loss = 0.3258\n",
            "Batch 190/455: Loss = 0.1625\n",
            "Skipping corrupted image: /content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/paper/paper 2273.jpg - cannot identify image file <_io.BufferedReader name='/content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/paper/paper 2273.jpg'>\n",
            "Batch 200/455: Loss = 0.1719\n",
            "Batch 210/455: Loss = 0.3847\n",
            "Batch 220/455: Loss = 0.3159\n",
            "Batch 230/455: Loss = 0.3636\n",
            "Batch 240/455: Loss = 0.2658\n",
            "Batch 250/455: Loss = 0.3898\n",
            "Batch 260/455: Loss = 0.1902\n",
            "Batch 270/455: Loss = 0.3536\n",
            "Batch 280/455: Loss = 0.0771\n",
            "Batch 290/455: Loss = 0.2766\n",
            "Batch 300/455: Loss = 0.1130\n",
            "Batch 310/455: Loss = 0.6057\n",
            "Batch 320/455: Loss = 0.2689\n",
            "Batch 330/455: Loss = 0.3751\n",
            "Batch 340/455: Loss = 0.5537\n",
            "Batch 350/455: Loss = 0.3839\n",
            "Skipping corrupted image: /content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/cardboard/cardboard 1075.jpg - cannot identify image file <_io.BufferedReader name='/content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/cardboard/cardboard 1075.jpg'>\n",
            "Batch 360/455: Loss = 0.1156\n",
            "Batch 370/455: Loss = 0.2941\n",
            "Batch 380/455: Loss = 0.0518\n",
            "Batch 390/455: Loss = 0.4762\n",
            "Batch 400/455: Loss = 0.4906\n",
            "Batch 410/455: Loss = 0.2938\n",
            "Batch 420/455: Loss = 0.2360\n",
            "Batch 430/455: Loss = 0.1910\n",
            "Batch 440/455: Loss = 0.3383\n",
            "Batch 450/455: Loss = 0.1974\n",
            "Training phase completed. Starting validation...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [4/25] completed.\n",
            "Train Loss: 0.2989 | Train Acc: 90.09%\n",
            "Val Loss: 0.4473 | Val Acc: 86.69%\n",
            "Precision: 87.53% | Recall: 86.02% | F1-score: 86.40%\n",
            "New best model saved at /content/drive/MyDrive/Waste Classification using Transfer Learning/Saved Models/VGG16/Model_VGG16.pth!\n",
            "\n",
            "Epoch 5/25 started...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 0/455: Loss = 0.2785\n",
            "Batch 10/455: Loss = 0.3384\n",
            "Batch 20/455: Loss = 0.0424\n",
            "Batch 30/455: Loss = 0.1722\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skipping corrupted image: /content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/cardboard/cardboard 1075.jpg - cannot identify image file <_io.BufferedReader name='/content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/cardboard/cardboard 1075.jpg'>\n",
            "Batch 40/455: Loss = 0.2310\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 50/455: Loss = 0.1687\n",
            "Batch 60/455: Loss = 0.0922\n",
            "Batch 70/455: Loss = 0.2507\n",
            "Batch 80/455: Loss = 0.2187\n",
            "Batch 90/455: Loss = 0.1821\n",
            "Batch 100/455: Loss = 0.1114\n",
            "Batch 110/455: Loss = 0.3339\n",
            "Skipping corrupted image: /content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/paper/paper 2273.jpg - cannot identify image file <_io.BufferedReader name='/content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/paper/paper 2273.jpg'>\n",
            "Batch 120/455: Loss = 0.1800\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 130/455: Loss = 0.5358\n",
            "Batch 140/455: Loss = 0.1655\n",
            "Batch 150/455: Loss = 0.2128\n",
            "Batch 160/455: Loss = 0.3022\n",
            "Batch 170/455: Loss = 0.2336\n",
            "Batch 180/455: Loss = 0.4012\n",
            "Batch 190/455: Loss = 0.2854\n",
            "Batch 200/455: Loss = 0.3985\n",
            "Batch 210/455: Loss = 0.3313\n",
            "Batch 220/455: Loss = 0.1368\n",
            "Batch 230/455: Loss = 0.1145\n",
            "Batch 240/455: Loss = 0.4079\n",
            "Batch 250/455: Loss = 0.1596\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 260/455: Loss = 0.0759\n",
            "Batch 270/455: Loss = 0.2064\n",
            "Batch 280/455: Loss = 0.1698\n",
            "Batch 290/455: Loss = 0.1040\n",
            "Batch 300/455: Loss = 0.1231\n",
            "Batch 310/455: Loss = 0.2355\n",
            "Batch 320/455: Loss = 0.2128\n",
            "Batch 330/455: Loss = 0.1574\n",
            "Batch 340/455: Loss = 0.1673\n",
            "Batch 350/455: Loss = 0.1787\n",
            "Batch 360/455: Loss = 0.0684\n",
            "Batch 370/455: Loss = 0.2565\n",
            "Batch 380/455: Loss = 0.1886\n",
            "Batch 390/455: Loss = 0.0313\n",
            "Batch 400/455: Loss = 0.0559\n",
            "Batch 410/455: Loss = 0.3446\n",
            "Skipping corrupted image: /content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/e-waste/e-waste 1719.jpg - cannot identify image file <_io.BufferedReader name='/content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/e-waste/e-waste 1719.jpg'>\n",
            "Batch 420/455: Loss = 0.4496\n",
            "Batch 430/455: Loss = 0.3358\n",
            "Batch 440/455: Loss = 0.2795\n",
            "Batch 450/455: Loss = 0.5089\n",
            "Training phase completed. Starting validation...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [5/25] completed.\n",
            "Train Loss: 0.2608 | Train Acc: 91.47%\n",
            "Val Loss: 0.5161 | Val Acc: 84.47%\n",
            "Precision: 85.52% | Recall: 84.26% | F1-score: 84.02%\n",
            "Checkpoint saved at /content/drive/MyDrive/Waste Classification using Transfer Learning/Saved Models/VGG16/checkpoint_epoch_5.pth!\n",
            "\n",
            "Epoch 6/25 started...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 0/455: Loss = 0.2088\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skipping corrupted image: /content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/cardboard/cardboard 1075.jpg - cannot identify image file <_io.BufferedReader name='/content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/cardboard/cardboard 1075.jpg'>\n",
            "Batch 10/455: Loss = 0.3305\n",
            "Batch 20/455: Loss = 0.6996\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 30/455: Loss = 0.2194\n",
            "Skipping corrupted image: /content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/e-waste/e-waste 1719.jpg - cannot identify image file <_io.BufferedReader name='/content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/e-waste/e-waste 1719.jpg'>\n",
            "Batch 40/455: Loss = 0.2255\n",
            "Batch 50/455: Loss = 0.2121\n",
            "Batch 60/455: Loss = 0.2466\n",
            "Batch 70/455: Loss = 0.1310\n",
            "Batch 80/455: Loss = 0.2157\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 90/455: Loss = 0.1469\n",
            "Batch 100/455: Loss = 0.1617\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 110/455: Loss = 0.0704\n",
            "Batch 120/455: Loss = 0.3074\n",
            "Batch 130/455: Loss = 0.1412\n",
            "Batch 140/455: Loss = 0.1935\n",
            "Batch 150/455: Loss = 0.1239\n",
            "Batch 160/455: Loss = 0.2079\n",
            "Batch 170/455: Loss = 0.0089\n",
            "Batch 180/455: Loss = 0.4089\n",
            "Skipping corrupted image: /content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/paper/paper 2273.jpg - cannot identify image file <_io.BufferedReader name='/content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/paper/paper 2273.jpg'>\n",
            "Batch 190/455: Loss = 0.4290\n",
            "Batch 200/455: Loss = 0.0949\n",
            "Batch 210/455: Loss = 0.1991\n",
            "Batch 220/455: Loss = 0.1937\n",
            "Batch 230/455: Loss = 0.2720\n",
            "Batch 240/455: Loss = 0.2083\n",
            "Batch 250/455: Loss = 0.2113\n",
            "Batch 260/455: Loss = 0.1807\n",
            "Batch 270/455: Loss = 0.1787\n",
            "Batch 280/455: Loss = 0.1985\n",
            "Batch 290/455: Loss = 0.1661\n",
            "Batch 300/455: Loss = 0.2563\n",
            "Batch 310/455: Loss = 0.3047\n",
            "Batch 320/455: Loss = 0.1543\n",
            "Batch 330/455: Loss = 0.1451\n",
            "Batch 340/455: Loss = 0.1219\n",
            "Batch 350/455: Loss = 0.1085\n",
            "Batch 360/455: Loss = 0.1587\n",
            "Batch 370/455: Loss = 0.1803\n",
            "Batch 380/455: Loss = 0.2727\n",
            "Batch 390/455: Loss = 0.2316\n",
            "Batch 400/455: Loss = 0.3205\n",
            "Batch 410/455: Loss = 0.2076\n",
            "Batch 420/455: Loss = 0.1078\n",
            "Batch 430/455: Loss = 0.1190\n",
            "Batch 440/455: Loss = 0.0882\n",
            "Batch 450/455: Loss = 0.4122\n",
            "Training phase completed. Starting validation...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [6/25] completed.\n",
            "Train Loss: 0.2196 | Train Acc: 92.62%\n",
            "Val Loss: 0.5034 | Val Acc: 84.04%\n",
            "Precision: 85.73% | Recall: 82.73% | F1-score: 83.40%\n",
            "\n",
            "Epoch 7/25 started...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 0/455: Loss = 0.0399\n",
            "Batch 10/455: Loss = 0.1552\n",
            "Batch 20/455: Loss = 0.2021\n",
            "Batch 30/455: Loss = 0.1422\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 40/455: Loss = 0.5912\n",
            "Batch 50/455: Loss = 0.0857\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 60/455: Loss = 0.2427\n",
            "Batch 70/455: Loss = 0.0979\n",
            "Batch 80/455: Loss = 0.3289\n",
            "Batch 90/455: Loss = 0.1153\n",
            "Batch 100/455: Loss = 0.1872\n",
            "Batch 110/455: Loss = 0.2224\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 120/455: Loss = 0.4267\n",
            "Skipping corrupted image: /content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/cardboard/cardboard 1075.jpg - cannot identify image file <_io.BufferedReader name='/content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/cardboard/cardboard 1075.jpg'>\n",
            "Batch 130/455: Loss = 0.2064\n",
            "Batch 140/455: Loss = 0.3815\n",
            "Batch 150/455: Loss = 0.1720\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 160/455: Loss = 0.1268\n",
            "Batch 170/455: Loss = 0.1129\n",
            "Batch 180/455: Loss = 0.1214\n",
            "Batch 190/455: Loss = 0.2570\n",
            "Batch 200/455: Loss = 0.4956\n",
            "Batch 210/455: Loss = 0.3747\n",
            "Batch 220/455: Loss = 0.1473\n",
            "Batch 230/455: Loss = 0.4674\n",
            "Batch 240/455: Loss = 0.1436\n",
            "Batch 250/455: Loss = 0.1768\n",
            "Batch 260/455: Loss = 0.4837\n",
            "Batch 270/455: Loss = 0.2581\n",
            "Batch 280/455: Loss = 0.0656\n",
            "Batch 290/455: Loss = 0.2764\n",
            "Batch 300/455: Loss = 0.0806\n",
            "Batch 310/455: Loss = 0.1430\n",
            "Batch 320/455: Loss = 0.1522\n",
            "Batch 330/455: Loss = 0.0658\n",
            "Batch 340/455: Loss = 0.0289\n",
            "Skipping corrupted image: /content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/e-waste/e-waste 1719.jpg - cannot identify image file <_io.BufferedReader name='/content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/e-waste/e-waste 1719.jpg'>\n",
            "Batch 350/455: Loss = 0.1077\n",
            "Batch 360/455: Loss = 0.2392\n",
            "Batch 370/455: Loss = 0.4608\n",
            "Batch 380/455: Loss = 0.1619\n",
            "Batch 390/455: Loss = 0.1280\n",
            "Batch 400/455: Loss = 0.3018\n",
            "Batch 410/455: Loss = 0.0760\n",
            "Batch 420/455: Loss = 0.1476\n",
            "Skipping corrupted image: /content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/paper/paper 2273.jpg - cannot identify image file <_io.BufferedReader name='/content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/paper/paper 2273.jpg'>\n",
            "Batch 430/455: Loss = 0.2477\n",
            "Batch 440/455: Loss = 0.0744\n",
            "Batch 450/455: Loss = 0.1471\n",
            "Training phase completed. Starting validation...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [7/25] completed.\n",
            "Train Loss: 0.2021 | Train Acc: 93.43%\n",
            "Val Loss: 0.4130 | Val Acc: 88.11%\n",
            "Precision: 88.55% | Recall: 87.39% | F1-score: 87.69%\n",
            "New best model saved at /content/drive/MyDrive/Waste Classification using Transfer Learning/Saved Models/VGG16/Model_VGG16.pth!\n",
            "\n",
            "Epoch 8/25 started...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 0/455: Loss = 0.2223\n",
            "Batch 10/455: Loss = 0.0441\n",
            "Batch 20/455: Loss = 0.6178\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 30/455: Loss = 0.0628\n",
            "Skipping corrupted image: /content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/cardboard/cardboard 1075.jpg - cannot identify image file <_io.BufferedReader name='/content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/cardboard/cardboard 1075.jpg'>\n",
            "Batch 40/455: Loss = 0.4250\n",
            "Batch 50/455: Loss = 0.0379\n",
            "Batch 60/455: Loss = 0.3925\n",
            "Batch 70/455: Loss = 0.1738\n",
            "Batch 80/455: Loss = 0.1411\n",
            "Batch 90/455: Loss = 0.1746\n",
            "Batch 100/455: Loss = 0.2316\n",
            "Batch 110/455: Loss = 0.1280\n",
            "Batch 120/455: Loss = 0.1235\n",
            "Batch 130/455: Loss = 0.1222\n",
            "Batch 140/455: Loss = 0.1819\n",
            "Batch 150/455: Loss = 0.1168\n",
            "Batch 160/455: Loss = 0.1871\n",
            "Batch 170/455: Loss = 0.2028\n",
            "Batch 180/455: Loss = 0.1113\n",
            "Batch 190/455: Loss = 0.1411\n",
            "Batch 200/455: Loss = 0.2910\n",
            "Batch 210/455: Loss = 0.1665\n",
            "Batch 220/455: Loss = 0.0813\n",
            "Batch 230/455: Loss = 0.2550\n",
            "Batch 240/455: Loss = 0.0545\n",
            "Batch 250/455: Loss = 0.2450\n",
            "Skipping corrupted image: /content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/e-waste/e-waste 1719.jpg - cannot identify image file <_io.BufferedReader name='/content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/e-waste/e-waste 1719.jpg'>\n",
            "Batch 260/455: Loss = 0.0920\n",
            "Batch 270/455: Loss = 0.1013\n",
            "Batch 280/455: Loss = 0.0854\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 290/455: Loss = 0.0949\n",
            "Skipping corrupted image: /content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/paper/paper 2273.jpg - cannot identify image file <_io.BufferedReader name='/content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/paper/paper 2273.jpg'>\n",
            "Batch 300/455: Loss = 0.2324\n",
            "Batch 310/455: Loss = 0.0828\n",
            "Batch 320/455: Loss = 0.1848\n",
            "Batch 330/455: Loss = 0.1214\n",
            "Batch 340/455: Loss = 0.1120\n",
            "Batch 350/455: Loss = 0.3846\n",
            "Batch 360/455: Loss = 0.1100\n",
            "Batch 370/455: Loss = 0.1998\n",
            "Batch 380/455: Loss = 0.2125\n",
            "Batch 390/455: Loss = 0.1625\n",
            "Batch 400/455: Loss = 0.0951\n",
            "Batch 410/455: Loss = 0.0344\n",
            "Batch 420/455: Loss = 0.1004\n",
            "Batch 430/455: Loss = 0.0444\n",
            "Batch 440/455: Loss = 0.2726\n",
            "Batch 450/455: Loss = 0.0297\n",
            "Training phase completed. Starting validation...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [8/25] completed.\n",
            "Train Loss: 0.1797 | Train Acc: 94.08%\n",
            "Val Loss: 0.4746 | Val Acc: 87.00%\n",
            "Precision: 87.55% | Recall: 86.44% | F1-score: 86.61%\n",
            "\n",
            "Epoch 9/25 started...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 0/455: Loss = 0.0854\n",
            "Batch 10/455: Loss = 0.0208\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 20/455: Loss = 0.0729\n",
            "Batch 30/455: Loss = 0.0388\n",
            "Batch 40/455: Loss = 0.0935\n",
            "Batch 50/455: Loss = 0.1270\n",
            "Batch 60/455: Loss = 0.1377\n",
            "Batch 70/455: Loss = 0.1735\n",
            "Skipping corrupted image: /content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/cardboard/cardboard 1075.jpg - cannot identify image file <_io.BufferedReader name='/content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/cardboard/cardboard 1075.jpg'>\n",
            "Batch 80/455: Loss = 0.0678\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 90/455: Loss = 0.2094\n",
            "Batch 100/455: Loss = 0.0557\n",
            "Batch 110/455: Loss = 0.0917\n",
            "Batch 120/455: Loss = 0.1584\n",
            "Batch 130/455: Loss = 0.2646\n",
            "Batch 140/455: Loss = 0.1057\n",
            "Batch 150/455: Loss = 0.1617\n",
            "Batch 160/455: Loss = 0.1097\n",
            "Batch 170/455: Loss = 0.2905\n",
            "Batch 180/455: Loss = 0.2479\n",
            "Batch 190/455: Loss = 0.1683\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 200/455: Loss = 0.1643\n",
            "Batch 210/455: Loss = 0.0136\n",
            "Skipping corrupted image: /content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/paper/paper 2273.jpg - cannot identify image file <_io.BufferedReader name='/content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/paper/paper 2273.jpg'>\n",
            "Batch 220/455: Loss = 0.3209\n",
            "Batch 230/455: Loss = 0.1345\n",
            "Batch 240/455: Loss = 0.5468\n",
            "Batch 250/455: Loss = 0.1619\n",
            "Batch 260/455: Loss = 0.1500\n",
            "Batch 270/455: Loss = 0.1366\n",
            "Batch 280/455: Loss = 0.0894\n",
            "Batch 290/455: Loss = 0.1039\n",
            "Batch 300/455: Loss = 0.1484\n",
            "Batch 310/455: Loss = 0.0803\n",
            "Batch 320/455: Loss = 0.2503\n",
            "Batch 330/455: Loss = 0.2970\n",
            "Skipping corrupted image: /content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/e-waste/e-waste 1719.jpg - cannot identify image file <_io.BufferedReader name='/content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/e-waste/e-waste 1719.jpg'>\n",
            "Batch 340/455: Loss = 0.0931\n",
            "Batch 350/455: Loss = 0.2346\n",
            "Batch 360/455: Loss = 0.0699\n",
            "Batch 370/455: Loss = 0.1343\n",
            "Batch 380/455: Loss = 0.0562\n",
            "Batch 390/455: Loss = 0.0890\n",
            "Batch 400/455: Loss = 0.1140\n",
            "Batch 410/455: Loss = 0.0616\n",
            "Batch 420/455: Loss = 0.0163\n",
            "Batch 430/455: Loss = 0.0835\n",
            "Batch 440/455: Loss = 0.0832\n",
            "Batch 450/455: Loss = 0.0858\n",
            "Training phase completed. Starting validation...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [9/25] completed.\n",
            "Train Loss: 0.1541 | Train Acc: 94.98%\n",
            "Val Loss: 0.5371 | Val Acc: 86.44%\n",
            "Precision: 87.07% | Recall: 85.86% | F1-score: 86.29%\n",
            "\n",
            "Epoch 10/25 started...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 0/455: Loss = 0.5827\n",
            "Skipping corrupted image: /content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/e-waste/e-waste 1719.jpg - cannot identify image file <_io.BufferedReader name='/content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/e-waste/e-waste 1719.jpg'>\n",
            "Batch 10/455: Loss = 0.0163\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 20/455: Loss = 0.0823\n",
            "Skipping corrupted image: /content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/paper/paper 2273.jpg - cannot identify image file <_io.BufferedReader name='/content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/paper/paper 2273.jpg'>\n",
            "Batch 30/455: Loss = 0.0225\n",
            "Batch 40/455: Loss = 0.0595\n",
            "Skipping corrupted image: /content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/cardboard/cardboard 1075.jpg - cannot identify image file <_io.BufferedReader name='/content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/cardboard/cardboard 1075.jpg'>\n",
            "Batch 50/455: Loss = 0.0874\n",
            "Batch 60/455: Loss = 0.0671\n",
            "Batch 70/455: Loss = 0.0066\n",
            "Batch 80/455: Loss = 0.0154\n",
            "Batch 90/455: Loss = 0.0537\n",
            "Batch 100/455: Loss = 0.0293\n",
            "Batch 110/455: Loss = 0.0690\n",
            "Batch 120/455: Loss = 0.2358\n",
            "Batch 130/455: Loss = 0.2318\n",
            "Batch 140/455: Loss = 0.2241\n",
            "Batch 150/455: Loss = 0.0474\n",
            "Batch 160/455: Loss = 0.1438\n",
            "Batch 170/455: Loss = 0.0767\n",
            "Batch 180/455: Loss = 0.0573\n",
            "Batch 190/455: Loss = 0.1032\n",
            "Batch 200/455: Loss = 0.0592\n",
            "Batch 210/455: Loss = 0.0390\n",
            "Batch 220/455: Loss = 0.0861\n",
            "Batch 230/455: Loss = 0.0927\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 240/455: Loss = 0.0428\n",
            "Batch 250/455: Loss = 0.0671\n",
            "Batch 260/455: Loss = 0.1693\n",
            "Batch 270/455: Loss = 0.1959\n",
            "Batch 280/455: Loss = 0.0633\n",
            "Batch 290/455: Loss = 0.3045\n",
            "Batch 300/455: Loss = 0.4731\n",
            "Batch 310/455: Loss = 0.2822\n",
            "Batch 320/455: Loss = 0.3494\n",
            "Batch 330/455: Loss = 0.0481\n",
            "Batch 340/455: Loss = 0.4548\n",
            "Batch 350/455: Loss = 0.1703\n",
            "Batch 360/455: Loss = 0.1117\n",
            "Batch 370/455: Loss = 0.1766\n",
            "Batch 380/455: Loss = 0.1346\n",
            "Batch 390/455: Loss = 0.1078\n",
            "Batch 400/455: Loss = 0.0175\n",
            "Batch 410/455: Loss = 0.1061\n",
            "Batch 420/455: Loss = 0.0554\n",
            "Batch 430/455: Loss = 0.1137\n",
            "Batch 440/455: Loss = 0.3107\n",
            "Batch 450/455: Loss = 0.0090\n",
            "Training phase completed. Starting validation...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/25] completed.\n",
            "Train Loss: 0.1451 | Train Acc: 95.08%\n",
            "Val Loss: 0.4820 | Val Acc: 88.05%\n",
            "Precision: 87.83% | Recall: 87.84% | F1-score: 87.72%\n",
            "Checkpoint saved at /content/drive/MyDrive/Waste Classification using Transfer Learning/Saved Models/VGG16/checkpoint_epoch_10.pth!\n",
            "\n",
            "Epoch 11/25 started...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 0/455: Loss = 0.0183\n",
            "Batch 10/455: Loss = 0.1439\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 20/455: Loss = 0.3377\n",
            "Batch 30/455: Loss = 0.0912\n",
            "Batch 40/455: Loss = 0.2134\n",
            "Batch 50/455: Loss = 0.0443\n",
            "Batch 60/455: Loss = 0.1596\n",
            "Batch 70/455: Loss = 0.0640\n",
            "Batch 80/455: Loss = 0.0769\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 90/455: Loss = 0.2301\n",
            "Batch 100/455: Loss = 0.3645\n",
            "Batch 110/455: Loss = 0.0712\n",
            "Batch 120/455: Loss = 0.0603\n",
            "Batch 130/455: Loss = 0.1348\n",
            "Batch 140/455: Loss = 0.0292\n",
            "Batch 150/455: Loss = 0.3237\n",
            "Skipping corrupted image: /content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/cardboard/cardboard 1075.jpg - cannot identify image file <_io.BufferedReader name='/content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/cardboard/cardboard 1075.jpg'>\n",
            "Batch 160/455: Loss = 0.1411\n",
            "Skipping corrupted image: /content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/paper/paper 2273.jpg - cannot identify image file <_io.BufferedReader name='/content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/paper/paper 2273.jpg'>\n",
            "Batch 170/455: Loss = 0.3345\n",
            "Batch 180/455: Loss = 0.1592\n",
            "Batch 190/455: Loss = 0.0778\n",
            "Batch 200/455: Loss = 0.1990\n",
            "Batch 210/455: Loss = 0.2927\n",
            "Batch 220/455: Loss = 0.0617\n",
            "Batch 230/455: Loss = 0.0094\n",
            "Batch 240/455: Loss = 0.0426\n",
            "Batch 250/455: Loss = 0.1184\n",
            "Batch 260/455: Loss = 0.0800\n",
            "Batch 270/455: Loss = 0.0537\n",
            "Skipping corrupted image: /content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/e-waste/e-waste 1719.jpg - cannot identify image file <_io.BufferedReader name='/content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/e-waste/e-waste 1719.jpg'>\n",
            "Batch 280/455: Loss = 0.1073\n",
            "Batch 290/455: Loss = 0.0809\n",
            "Batch 300/455: Loss = 0.1045\n",
            "Batch 310/455: Loss = 0.0634\n",
            "Batch 320/455: Loss = 0.0370\n",
            "Batch 330/455: Loss = 0.2040\n",
            "Batch 340/455: Loss = 0.0629\n",
            "Batch 350/455: Loss = 0.0858\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 360/455: Loss = 0.0931\n",
            "Batch 370/455: Loss = 0.1196\n",
            "Batch 380/455: Loss = 0.1284\n",
            "Batch 390/455: Loss = 0.0793\n",
            "Batch 400/455: Loss = 0.5208\n",
            "Batch 410/455: Loss = 0.0835\n",
            "Batch 420/455: Loss = 0.0954\n",
            "Batch 430/455: Loss = 0.0824\n",
            "Batch 440/455: Loss = 0.0158\n",
            "Batch 450/455: Loss = 0.0666\n",
            "Training phase completed. Starting validation...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [11/25] completed.\n",
            "Train Loss: 0.1219 | Train Acc: 96.15%\n",
            "Val Loss: 0.4914 | Val Acc: 89.40%\n",
            "Precision: 89.95% | Recall: 88.44% | F1-score: 88.86%\n",
            "New best model saved at /content/drive/MyDrive/Waste Classification using Transfer Learning/Saved Models/VGG16/Model_VGG16.pth!\n",
            "\n",
            "Epoch 12/25 started...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 0/455: Loss = 0.0152\n",
            "Batch 10/455: Loss = 0.0472\n",
            "Skipping corrupted image: /content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/e-waste/e-waste 1719.jpg - cannot identify image file <_io.BufferedReader name='/content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/e-waste/e-waste 1719.jpg'>\n",
            "Batch 20/455: Loss = 0.1814\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 30/455: Loss = 0.1241\n",
            "Skipping corrupted image: /content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/paper/paper 2273.jpg - cannot identify image file <_io.BufferedReader name='/content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/paper/paper 2273.jpg'>\n",
            "Batch 40/455: Loss = 0.0778\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 50/455: Loss = 0.3637\n",
            "Batch 60/455: Loss = 0.0429\n",
            "Batch 70/455: Loss = 0.1475\n",
            "Batch 80/455: Loss = 0.2107\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 90/455: Loss = 0.1403\n",
            "Batch 100/455: Loss = 0.1773\n",
            "Batch 110/455: Loss = 0.2230\n",
            "Batch 120/455: Loss = 0.0682\n",
            "Batch 130/455: Loss = 0.3120\n",
            "Batch 140/455: Loss = 0.0360\n",
            "Batch 150/455: Loss = 0.2550\n",
            "Batch 160/455: Loss = 0.0633\n",
            "Batch 170/455: Loss = 0.0670\n",
            "Skipping corrupted image: /content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/cardboard/cardboard 1075.jpg - cannot identify image file <_io.BufferedReader name='/content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/cardboard/cardboard 1075.jpg'>\n",
            "Batch 180/455: Loss = 0.2640\n",
            "Batch 190/455: Loss = 0.0960\n",
            "Batch 200/455: Loss = 0.1714\n",
            "Batch 210/455: Loss = 0.2660\n",
            "Batch 220/455: Loss = 0.4210\n",
            "Batch 230/455: Loss = 0.0735\n",
            "Batch 240/455: Loss = 0.0430\n",
            "Batch 250/455: Loss = 0.0123\n",
            "Batch 260/455: Loss = 0.1328\n",
            "Batch 270/455: Loss = 0.2529\n",
            "Batch 280/455: Loss = 0.1302\n",
            "Batch 290/455: Loss = 0.0347\n",
            "Batch 300/455: Loss = 0.0903\n",
            "Batch 310/455: Loss = 0.0644\n",
            "Batch 320/455: Loss = 0.5157\n",
            "Batch 330/455: Loss = 0.0928\n",
            "Batch 340/455: Loss = 0.2539\n",
            "Batch 350/455: Loss = 0.0998\n",
            "Batch 360/455: Loss = 0.0137\n",
            "Batch 370/455: Loss = 0.0972\n",
            "Batch 380/455: Loss = 0.0546\n",
            "Batch 390/455: Loss = 0.0149\n",
            "Batch 400/455: Loss = 0.0518\n",
            "Batch 410/455: Loss = 0.0128\n",
            "Batch 420/455: Loss = 0.2345\n",
            "Batch 430/455: Loss = 0.2253\n",
            "Batch 440/455: Loss = 0.0196\n",
            "Batch 450/455: Loss = 0.0101\n",
            "Training phase completed. Starting validation...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [12/25] completed.\n",
            "Train Loss: 0.1378 | Train Acc: 95.56%\n",
            "Val Loss: 0.4464 | Val Acc: 88.29%\n",
            "Precision: 88.59% | Recall: 87.50% | F1-score: 87.84%\n",
            "\n",
            "Epoch 13/25 started...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 0/455: Loss = 0.0184\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 10/455: Loss = 0.4004\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 20/455: Loss = 0.0800\n",
            "Batch 30/455: Loss = 0.2500\n",
            "Batch 40/455: Loss = 0.0680\n",
            "Batch 50/455: Loss = 0.0727\n",
            "Batch 60/455: Loss = 0.1660\n",
            "Skipping corrupted image: /content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/paper/paper 2273.jpg - cannot identify image file <_io.BufferedReader name='/content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/paper/paper 2273.jpg'>\n",
            "Batch 70/455: Loss = 0.0686\n",
            "Batch 80/455: Loss = 0.0062\n",
            "Batch 90/455: Loss = 0.0132\n",
            "Batch 100/455: Loss = 0.2357\n",
            "Batch 110/455: Loss = 0.0461\n",
            "Batch 120/455: Loss = 0.2474\n",
            "Batch 130/455: Loss = 0.0847\n",
            "Batch 140/455: Loss = 0.0265\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 150/455: Loss = 0.2242\n",
            "Batch 160/455: Loss = 0.0356\n",
            "Batch 170/455: Loss = 0.1488\n",
            "Batch 180/455: Loss = 0.0635\n",
            "Batch 190/455: Loss = 0.2193\n",
            "Batch 200/455: Loss = 0.1322\n",
            "Batch 210/455: Loss = 0.1408\n",
            "Batch 220/455: Loss = 0.2492\n",
            "Batch 230/455: Loss = 0.1810\n",
            "Batch 240/455: Loss = 0.0953\n",
            "Batch 250/455: Loss = 0.0793\n",
            "Batch 260/455: Loss = 0.0264\n",
            "Batch 270/455: Loss = 0.1050\n",
            "Batch 280/455: Loss = 0.2567\n",
            "Batch 290/455: Loss = 0.2888\n",
            "Skipping corrupted image: /content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/e-waste/e-waste 1719.jpg - cannot identify image file <_io.BufferedReader name='/content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/e-waste/e-waste 1719.jpg'>\n",
            "Batch 300/455: Loss = 0.1202\n",
            "Batch 310/455: Loss = 0.1682\n",
            "Batch 320/455: Loss = 0.1599\n",
            "Batch 330/455: Loss = 0.1577\n",
            "Batch 340/455: Loss = 0.1386\n",
            "Batch 350/455: Loss = 0.0708\n",
            "Skipping corrupted image: /content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/cardboard/cardboard 1075.jpg - cannot identify image file <_io.BufferedReader name='/content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/cardboard/cardboard 1075.jpg'>\n",
            "Batch 360/455: Loss = 0.0756\n",
            "Batch 370/455: Loss = 0.0052\n",
            "Batch 380/455: Loss = 0.1877\n",
            "Batch 390/455: Loss = 0.1826\n",
            "Batch 400/455: Loss = 0.1785\n",
            "Batch 410/455: Loss = 0.0669\n",
            "Batch 420/455: Loss = 0.0503\n",
            "Batch 430/455: Loss = 0.2299\n",
            "Batch 440/455: Loss = 0.0422\n",
            "Batch 450/455: Loss = 0.0285\n",
            "Training phase completed. Starting validation...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [13/25] completed.\n",
            "Train Loss: 0.1254 | Train Acc: 95.87%\n",
            "Val Loss: 0.5542 | Val Acc: 86.32%\n",
            "Precision: 87.28% | Recall: 86.07% | F1-score: 86.09%\n",
            "\n",
            "Epoch 14/25 started...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 0/455: Loss = 0.0237\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 10/455: Loss = 0.3556\n",
            "Batch 20/455: Loss = 0.0306\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 30/455: Loss = 0.0167\n",
            "Batch 40/455: Loss = 0.0174\n",
            "Skipping corrupted image: /content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/paper/paper 2273.jpg - cannot identify image file <_io.BufferedReader name='/content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/paper/paper 2273.jpg'>\n",
            "Batch 50/455: Loss = 0.1471\n",
            "Batch 60/455: Loss = 0.0310\n",
            "Batch 70/455: Loss = 0.0480\n",
            "Batch 80/455: Loss = 0.1559\n",
            "Batch 90/455: Loss = 0.0193\n",
            "Batch 100/455: Loss = 0.1235\n",
            "Batch 110/455: Loss = 0.1357\n",
            "Batch 120/455: Loss = 0.0825\n",
            "Batch 130/455: Loss = 0.0273\n",
            "Batch 140/455: Loss = 0.1646\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skipping corrupted image: /content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/cardboard/cardboard 1075.jpg - cannot identify image file <_io.BufferedReader name='/content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/cardboard/cardboard 1075.jpg'>\n",
            "Batch 150/455: Loss = 0.0059\n",
            "Batch 160/455: Loss = 0.0822\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 170/455: Loss = 0.2820\n",
            "Batch 180/455: Loss = 0.1109\n",
            "Batch 190/455: Loss = 0.1246\n",
            "Batch 200/455: Loss = 0.1656\n",
            "Batch 210/455: Loss = 0.1197\n",
            "Batch 220/455: Loss = 0.0372\n",
            "Batch 230/455: Loss = 0.1505\n",
            "Batch 240/455: Loss = 0.2353\n",
            "Batch 250/455: Loss = 0.3180\n",
            "Batch 260/455: Loss = 0.0431\n",
            "Batch 270/455: Loss = 0.0739\n",
            "Batch 280/455: Loss = 0.0581\n",
            "Batch 290/455: Loss = 0.0301\n",
            "Batch 300/455: Loss = 0.2251\n",
            "Batch 310/455: Loss = 0.1479\n",
            "Batch 320/455: Loss = 0.0733\n",
            "Batch 330/455: Loss = 0.0069\n",
            "Batch 340/455: Loss = 0.0519\n",
            "Batch 350/455: Loss = 0.0439\n",
            "Batch 360/455: Loss = 0.0521\n",
            "Batch 370/455: Loss = 0.0043\n",
            "Batch 380/455: Loss = 0.0456\n",
            "Batch 390/455: Loss = 0.0090\n",
            "Batch 400/455: Loss = 0.3123\n",
            "Batch 410/455: Loss = 0.2594\n",
            "Batch 420/455: Loss = 0.0114\n",
            "Batch 430/455: Loss = 0.2062\n",
            "Batch 440/455: Loss = 0.1350\n",
            "Skipping corrupted image: /content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/e-waste/e-waste 1719.jpg - cannot identify image file <_io.BufferedReader name='/content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/e-waste/e-waste 1719.jpg'>\n",
            "Batch 450/455: Loss = 0.0887\n",
            "Training phase completed. Starting validation...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [14/25] completed.\n",
            "Train Loss: 0.1103 | Train Acc: 96.31%\n",
            "Val Loss: 0.5012 | Val Acc: 89.16%\n",
            "Precision: 89.02% | Recall: 89.22% | F1-score: 88.82%\n",
            "\n",
            "Epoch 15/25 started...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 0/455: Loss = 0.0785\n",
            "Batch 10/455: Loss = 0.0719\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 20/455: Loss = 0.1243\n",
            "Batch 30/455: Loss = 0.1465\n",
            "Batch 40/455: Loss = 0.0183\n",
            "Batch 50/455: Loss = 0.0780\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 60/455: Loss = 0.1002\n",
            "Batch 70/455: Loss = 0.3365\n",
            "Batch 80/455: Loss = 0.0873\n",
            "Batch 90/455: Loss = 0.0972\n",
            "Batch 100/455: Loss = 0.2877\n",
            "Batch 110/455: Loss = 0.0056\n",
            "Batch 120/455: Loss = 0.0650\n",
            "Batch 130/455: Loss = 0.1639\n",
            "Batch 140/455: Loss = 0.0356\n",
            "Batch 150/455: Loss = 0.0566\n",
            "Batch 160/455: Loss = 0.0844\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 170/455: Loss = 0.0144\n",
            "Batch 180/455: Loss = 0.2045\n",
            "Batch 190/455: Loss = 0.0641\n",
            "Batch 200/455: Loss = 0.0363\n",
            "Batch 210/455: Loss = 0.1612\n",
            "Batch 220/455: Loss = 0.3052\n",
            "Batch 230/455: Loss = 0.2060\n",
            "Batch 240/455: Loss = 0.1835\n",
            "Batch 250/455: Loss = 0.1198\n",
            "Batch 260/455: Loss = 0.1068\n",
            "Batch 270/455: Loss = 0.0109\n",
            "Batch 280/455: Loss = 0.0717\n",
            "Batch 290/455: Loss = 0.0134\n",
            "Batch 300/455: Loss = 0.3321\n",
            "Batch 310/455: Loss = 0.0567\n",
            "Batch 320/455: Loss = 0.2605\n",
            "Batch 330/455: Loss = 0.2841\n",
            "Batch 340/455: Loss = 0.2385\n",
            "Batch 350/455: Loss = 0.0529\n",
            "Batch 360/455: Loss = 0.2711\n",
            "Batch 370/455: Loss = 0.3595\n",
            "Skipping corrupted image: /content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/paper/paper 2273.jpg - cannot identify image file <_io.BufferedReader name='/content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/paper/paper 2273.jpg'>\n",
            "Batch 380/455: Loss = 0.0196\n",
            "Batch 390/455: Loss = 0.0538\n",
            "Skipping corrupted image: /content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/cardboard/cardboard 1075.jpg - cannot identify image file <_io.BufferedReader name='/content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/cardboard/cardboard 1075.jpg'>\n",
            "Batch 400/455: Loss = 0.0732\n",
            "Skipping corrupted image: /content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/e-waste/e-waste 1719.jpg - cannot identify image file <_io.BufferedReader name='/content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/e-waste/e-waste 1719.jpg'>\n",
            "Batch 410/455: Loss = 0.0615\n",
            "Batch 420/455: Loss = 0.0061\n",
            "Batch 430/455: Loss = 0.0590\n",
            "Batch 440/455: Loss = 0.0962\n",
            "Batch 450/455: Loss = 0.0908\n",
            "Training phase completed. Starting validation...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [15/25] completed.\n",
            "Train Loss: 0.1119 | Train Acc: 96.52%\n",
            "Val Loss: 0.5297 | Val Acc: 87.49%\n",
            "Precision: 87.62% | Recall: 87.18% | F1-score: 87.24%\n",
            "Checkpoint saved at /content/drive/MyDrive/Waste Classification using Transfer Learning/Saved Models/VGG16/checkpoint_epoch_15.pth!\n",
            "\n",
            "Epoch 16/25 started...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 0/455: Loss = 0.0182\n",
            "Skipping corrupted image: /content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/e-waste/e-waste 1719.jpg - cannot identify image file <_io.BufferedReader name='/content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/e-waste/e-waste 1719.jpg'>\n",
            "Batch 10/455: Loss = 0.0070\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 20/455: Loss = 0.1626\n",
            "Batch 30/455: Loss = 0.0600\n",
            "Batch 40/455: Loss = 0.0285\n",
            "Batch 50/455: Loss = 0.0139\n",
            "Batch 60/455: Loss = 0.1358\n",
            "Batch 70/455: Loss = 0.1824\n",
            "Batch 80/455: Loss = 0.1363\n",
            "Batch 90/455: Loss = 0.0989\n",
            "Batch 100/455: Loss = 0.1175\n",
            "Batch 110/455: Loss = 0.0917\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 120/455: Loss = 0.2393\n",
            "Batch 130/455: Loss = 0.0172\n",
            "Batch 140/455: Loss = 0.1365\n",
            "Batch 150/455: Loss = 0.1048\n",
            "Batch 160/455: Loss = 0.0560\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 170/455: Loss = 0.0658\n",
            "Batch 180/455: Loss = 0.0886\n",
            "Batch 190/455: Loss = 0.0060\n",
            "Batch 200/455: Loss = 0.0700\n",
            "Batch 210/455: Loss = 0.4087\n",
            "Batch 220/455: Loss = 0.0486\n",
            "Batch 230/455: Loss = 0.1730\n",
            "Batch 240/455: Loss = 0.3409\n",
            "Skipping corrupted image: /content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/paper/paper 2273.jpg - cannot identify image file <_io.BufferedReader name='/content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/paper/paper 2273.jpg'>\n",
            "Batch 250/455: Loss = 0.0546\n",
            "Batch 260/455: Loss = 0.1770\n",
            "Batch 270/455: Loss = 0.0766\n",
            "Batch 280/455: Loss = 0.1040\n",
            "Batch 290/455: Loss = 0.1176\n",
            "Batch 300/455: Loss = 0.1563\n",
            "Batch 310/455: Loss = 0.1952\n",
            "Batch 320/455: Loss = 0.1099\n",
            "Batch 330/455: Loss = 0.0468\n",
            "Batch 340/455: Loss = 0.0470\n",
            "Batch 350/455: Loss = 0.1259\n",
            "Skipping corrupted image: /content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/cardboard/cardboard 1075.jpg - cannot identify image file <_io.BufferedReader name='/content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/cardboard/cardboard 1075.jpg'>\n",
            "Batch 360/455: Loss = 0.0369\n",
            "Batch 370/455: Loss = 0.1123\n",
            "Batch 380/455: Loss = 0.0349\n",
            "Batch 390/455: Loss = 0.0199\n",
            "Batch 400/455: Loss = 0.0609\n",
            "Batch 410/455: Loss = 0.1231\n",
            "Batch 420/455: Loss = 0.1209\n",
            "Batch 430/455: Loss = 0.1268\n",
            "Batch 440/455: Loss = 0.1426\n",
            "Batch 450/455: Loss = 0.1081\n",
            "Training phase completed. Starting validation...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [16/25] completed.\n",
            "Train Loss: 0.1071 | Train Acc: 96.41%\n",
            "Val Loss: 0.4805 | Val Acc: 88.60%\n",
            "Precision: 88.63% | Recall: 88.45% | F1-score: 88.49%\n",
            "Early stopping at epoch 16 due to no improvement in validation loss or accuracy.\n",
            "Training complete!\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision.models import (\n",
        "    resnet50, ResNet50_Weights,\n",
        "    resnet34, ResNet34_Weights,\n",
        "    efficientnet_b0, EfficientNet_B0_Weights,\n",
        "    efficientnet_b3, EfficientNet_B3_Weights,\n",
        "    vgg16, VGG16_Weights,\n",
        "    densenet121, DenseNet121_Weights,\n",
        "    mobilenet_v2, MobileNet_V2_Weights,\n",
        "    inception_v3, Inception_V3_Weights\n",
        ")\n",
        "\n",
        "# Set device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Select the model\n",
        "selected_model_name = \"VGG16\"  # Change this to train other models\n",
        "\n",
        "# Define models\n",
        "models_list = {\n",
        "    \"ResNet-50\": resnet50(weights=ResNet50_Weights.IMAGENET1K_V1),\n",
        "    \"ResNet-34\": resnet34(weights=ResNet34_Weights.IMAGENET1K_V1),\n",
        "    \"EfficientNet-B0\": efficientnet_b0(weights=EfficientNet_B0_Weights.IMAGENET1K_V1),\n",
        "    \"EfficientNet-B3\": efficientnet_b3(weights=EfficientNet_B3_Weights.IMAGENET1K_V1),\n",
        "    \"VGG16\": vgg16(weights=VGG16_Weights.IMAGENET1K_V1),\n",
        "    \"DenseNet-121\": densenet121(weights=DenseNet121_Weights.IMAGENET1K_V1),\n",
        "    \"MobileNet-V2\": mobilenet_v2(weights=MobileNet_V2_Weights.IMAGENET1K_V1),\n",
        "    \"Inception-V3\": inception_v3(weights=Inception_V3_Weights.IMAGENET1K_V1)\n",
        "}\n",
        "\n",
        "# Get the selected model\n",
        "model = models_list[selected_model_name]\n",
        "print(f\"\\nTraining {selected_model_name}...\\n\")\n",
        "\n",
        "# Adjust the final layer for 7 classes based on the model type\n",
        "if \"resnet\" in selected_model_name.lower():\n",
        "    num_features = model.fc.in_features\n",
        "    model.fc = nn.Linear(num_features, 7)\n",
        "elif \"efficientnet\" in selected_model_name.lower():\n",
        "    num_features = model.classifier[1].in_features if hasattr(model.classifier, \"__getitem__\") else model.classifier.in_features\n",
        "    model.classifier = nn.Linear(num_features, 7)\n",
        "elif \"densenet\" in selected_model_name.lower():\n",
        "    num_features = model.classifier.in_features\n",
        "    model.classifier = nn.Linear(num_features, 7)\n",
        "elif \"vgg\" in selected_model_name.lower():\n",
        "    num_features = model.classifier[6].in_features\n",
        "    model.classifier[6] = nn.Linear(num_features, 7)\n",
        "elif \"mobilenet\" in selected_model_name.lower():\n",
        "    num_features = model.classifier[1].in_features if hasattr(model.classifier, \"__getitem__\") else model.classifier.in_features\n",
        "    model.classifier = nn.Linear(num_features, 7)\n",
        "elif \"inception\" in selected_model_name.lower():\n",
        "    num_features = model.fc.in_features\n",
        "    model.fc = nn.Linear(num_features, 7)\n",
        "    if model.aux_logits:  # Inception has an auxiliary classifier\n",
        "        num_features_aux = model.AuxLogits.fc.in_features\n",
        "        model.AuxLogits.fc = nn.Linear(num_features_aux, 7)\n",
        "\n",
        "# Move model to the device (CPU/GPU)\n",
        "model = model.to(device)\n",
        "model.train()  # Ensure the model is in training mode\n",
        "\n",
        "# Define Loss Function and Optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001, weight_decay=1e-4)\n",
        "\n",
        "# Learning rate scheduler\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3, verbose=True)\n",
        "\n",
        "# Train the model\n",
        "train_losses, val_losses, train_accs, val_accs = train_model(\n",
        "    model=model,\n",
        "    model_name=selected_model_name,\n",
        "    criterion=criterion,\n",
        "    optimizer=optimizer,\n",
        "    train_loader=train_loader,\n",
        "    val_loader=val_loader,\n",
        "    device=device,\n",
        "    num_epochs=25,\n",
        "    patience=5,\n",
        "    scheduler=scheduler\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-FO-gOGmfCVr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7824a9cd-b427-428c-adb8-f372fc794f33"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved successfully in /content/drive/MyDrive/Waste Classification using Transfer Learning/Saved Models/Model_VGG16.pth\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "# Define the folder path\n",
        "save_path = \"/content/drive/MyDrive/Waste Classification using Transfer Learning/Saved Models\"\n",
        "# os.makedirs(save_path, exist_ok=True)  # Create folder if it doesn't exist\n",
        "torch.save(model, os.path.join(save_path, \"Model_VGG16.pth\"))\n",
        "print(f\"Model saved successfully in {save_path}/Model_VGG16.pth\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}