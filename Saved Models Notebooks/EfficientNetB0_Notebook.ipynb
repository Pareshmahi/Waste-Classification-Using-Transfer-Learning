{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PPH8BVT0Q9b9",
        "outputId": "f224a388-ec4d-4c50-ad30-a50d171f7e5c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision torchaudio\n",
        "!pip install tqdm matplotlib scikit-learn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AQcus6fZSR4y",
        "outputId": "7f031968-4bd0-4059-eb6a-f7e62bd0d94e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m113.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m88.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m57.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m42.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.14.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import time\n",
        "import os\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision.datasets import ImageFolder\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from tqdm import tqdm\n",
        "from PIL import Image"
      ],
      "metadata": {
        "id": "8PujdC_ZSv7J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if CUDA (GPU support) is available\n",
        "if torch.cuda.is_available():\n",
        "    # Get the number of available GPUs\n",
        "    num_gpus = torch.cuda.device_count()\n",
        "    print(f\"Number of GPUs available: {num_gpus}\")\n",
        "\n",
        "    # Get the name of the current GPU\n",
        "    gpu_name = torch.cuda.get_device_name(torch.cuda.current_device())\n",
        "    print(f\"Current GPU: {gpu_name}\")\n",
        "\n",
        "    # Get GPU device properties\n",
        "    device = torch.device('cuda')\n",
        "    print(f\"Device type: {device.type}\")\n",
        "else:\n",
        "    print(\"CUDA is not available. PyTorch will run on the CPU.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VB_vXA04TOyn",
        "outputId": "28c4081d-7e4b-47d5-b662-ab62d8957f26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of GPUs available: 1\n",
            "Current GPU: Tesla T4\n",
            "Device type: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Standard image size for CNNs\n",
        "image_size = 224\n",
        "\n",
        "# Custom dataset class to handle corrupt images\n",
        "class CustomImageFolder(ImageFolder):\n",
        "    def __getitem__(self, index):\n",
        "        try:\n",
        "            return super().__getitem__(index)\n",
        "        except Exception as e:\n",
        "            print(f\"Skipping corrupted image: {self.imgs[index][0]} - {e}\")\n",
        "            return self.__getitem__((index + 1) % len(self.imgs))  # Get next valid image\n",
        "\n",
        "# Optimized Transformations (SAME FOR ALL MODELS)\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.Resize((image_size, image_size)),\n",
        "    transforms.Lambda(lambda img: img.convert('RGB')),  # Ensures all images are RGB\n",
        "    transforms.RandomHorizontalFlip(p=0.5),  # Flip 50% of the time\n",
        "    transforms.RandomRotation(10),  # Rotate within ±10 degrees\n",
        "    transforms.RandomResizedCrop(image_size, scale=(0.8, 1.0)),  # Random cropping\n",
        "    transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.05),  # Color variation\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])  # Standard normalization\n",
        "])\n",
        "\n",
        "val_transforms = transforms.Compose([\n",
        "    transforms.Resize((image_size, image_size)),\n",
        "    transforms.Lambda(lambda img: img.convert('RGB')),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Paths\n",
        "dataset_path = \"/content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset\"\n",
        "validation_path = \"/content/drive/MyDrive/Waste Classification using Transfer Learning/Data Validation\"\n",
        "\n",
        "# Hyperparameters (Optimized for Performance)\n",
        "batch_size = 32  # Changed from 64 to 32\n",
        "num_workers = 4  # Parallel data loading\n",
        "\n",
        "# Load dataset with corrupt image handling\n",
        "train_dataset = CustomImageFolder(root=dataset_path, transform=train_transforms)\n",
        "val_dataset = CustomImageFolder(root=validation_path, transform=val_transforms)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
        "\n",
        "# Print class names to verify\n",
        "print(\"Classes:\", train_dataset.classes)\n",
        "\n",
        "# Function to check for corrupt images before training\n",
        "def check_corrupt_images(dataset_path):\n",
        "    print(\"Checking dataset for corrupt images...\")\n",
        "    for folder in os.listdir(dataset_path):\n",
        "        folder_path = os.path.join(dataset_path, folder)\n",
        "        if os.path.isdir(folder_path):\n",
        "            for file in os.listdir(folder_path):\n",
        "                file_path = os.path.join(folder_path, file)\n",
        "                try:\n",
        "                    with Image.open(file_path) as img:\n",
        "                        img.verify()  # Verify image integrity\n",
        "                except:\n",
        "                    print(f\"Corrupt or non-image file found: {file_path}\")\n",
        "\n",
        "# Run dataset check\n",
        "check_corrupt_images(dataset_path)\n",
        "check_corrupt_images(validation_path)\n",
        "\n",
        "print(\"Dataset loaded successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3TKp-8q4UN4Y",
        "outputId": "637f9cd4-a6a6-41e5-ad22-d97fce39f13c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classes: ['cardboard', 'e-waste', 'glass', 'medical', 'metal', 'paper', 'plastic']\n",
            "Checking dataset for corrupt images...\n",
            "Corrupt or non-image file found: /content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/e-waste/e-waste 1719.jpg\n",
            "Corrupt or non-image file found: /content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/cardboard/cardboard 1075.jpg\n",
            "Corrupt or non-image file found: /content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/paper/paper 2273.jpg\n",
            "Checking dataset for corrupt images...\n",
            "Dataset loaded successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, model_name, criterion, optimizer, train_loader, val_loader, device, num_epochs=25, patience=5, scheduler=None):\n",
        "    train_losses, val_losses, train_accs, val_accs = [], [], [], []\n",
        "    best_val_acc = 0  # Track best validation accuracy\n",
        "    best_val_loss = float('inf')  # Track best validation loss\n",
        "    patience_counter = 0\n",
        "\n",
        "    # Create directory for saving models\n",
        "    save_dir = os.path.join(\"/content/drive/MyDrive/Waste Classification using Transfer Learning/Saved Models\", model_name)\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "    print(\"Starting training...\")\n",
        "\n",
        "    for epoch in range(1, num_epochs + 1):\n",
        "        print(f\"\\nEpoch {epoch}/{num_epochs} started...\")\n",
        "        model.train()\n",
        "        running_loss, correct, total = 0.0, 0, 0\n",
        "\n",
        "        for batch_idx, (inputs, labels) in enumerate(train_loader):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "            if batch_idx % 10 == 0:\n",
        "                print(f\"Batch {batch_idx}/{len(train_loader)}: Loss = {loss.item():.4f}\")\n",
        "\n",
        "        train_loss = running_loss / len(train_loader)\n",
        "        train_acc = (correct / total) * 100\n",
        "\n",
        "        print(\"Training phase completed. Starting validation...\")\n",
        "\n",
        "        # Validation Phase\n",
        "        model.eval()\n",
        "        val_loss, val_correct, val_total = 0.0, 0, 0\n",
        "        all_preds, all_labels = [], []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch_idx, (inputs, labels) in enumerate(val_loader):\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                val_loss += loss.item()\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "                val_total += labels.size(0)\n",
        "                val_correct += (predicted == labels).sum().item()\n",
        "\n",
        "                all_preds.extend(predicted.cpu().numpy())\n",
        "                all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "        val_loss /= len(val_loader)\n",
        "        val_acc = (val_correct / val_total) * 100\n",
        "\n",
        "        # Compute Precision, Recall, and F1-score\n",
        "        precision = precision_score(all_labels, all_preds, average='macro') * 100\n",
        "        recall = recall_score(all_labels, all_preds, average='macro') * 100\n",
        "        f1 = f1_score(all_labels, all_preds, average='macro') * 100\n",
        "\n",
        "        # Store metrics\n",
        "        train_losses.append(train_loss)\n",
        "        val_losses.append(val_loss)\n",
        "        train_accs.append(train_acc)\n",
        "        val_accs.append(val_acc)\n",
        "\n",
        "        # Print Metrics for Each Epoch\n",
        "        print(f\"Epoch [{epoch}/{num_epochs}] completed.\")\n",
        "        print(f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}%\")\n",
        "        print(f\"Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.2f}%\")\n",
        "        print(f\"Precision: {precision:.2f}% | Recall: {recall:.2f}% | F1-score: {f1:.2f}%\")\n",
        "\n",
        "        # Save checkpoint every 5 epochs\n",
        "        if epoch % 5 == 0:\n",
        "            checkpoint_path = os.path.join(save_dir, f'checkpoint_epoch_{epoch}.pth')\n",
        "            checkpoint = {\n",
        "                'epoch': epoch,\n",
        "                'model_state_dict': model.state_dict(),\n",
        "                'optimizer_state_dict': optimizer.state_dict(),\n",
        "                'train_loss': train_loss,\n",
        "                'val_loss': val_loss,\n",
        "                'val_acc': val_acc\n",
        "            }\n",
        "            torch.save(checkpoint, checkpoint_path)\n",
        "            print(f\"Checkpoint saved at {checkpoint_path}!\")\n",
        "\n",
        "        # Save best model (based on validation accuracy or loss)\n",
        "        if val_loss < best_val_loss or val_acc > best_val_acc:\n",
        "            best_val_loss = min(best_val_loss, val_loss)\n",
        "            best_val_acc = max(best_val_acc, val_acc)\n",
        "            patience_counter = 0  # Reset patience counter\n",
        "\n",
        "            best_model_path = os.path.join(save_dir, 'Model_EfficientNetB0.pth')\n",
        "            torch.save({\n",
        "                'epoch': epoch,\n",
        "                'model_state_dict': model.state_dict(),\n",
        "                'optimizer_state_dict': optimizer.state_dict(),\n",
        "                'train_loss': train_loss,\n",
        "                'val_loss': val_loss,\n",
        "                'val_acc': val_acc\n",
        "            }, best_model_path)\n",
        "\n",
        "            print(f\"New best model saved at {best_model_path}!\")\n",
        "        else:\n",
        "            patience_counter += 1  # Increment counter if no improvement\n",
        "\n",
        "        # Early Stopping Condition\n",
        "        if patience_counter >= patience:\n",
        "            print(f\"Early stopping at epoch {epoch} due to no improvement in validation loss or accuracy.\")\n",
        "            break\n",
        "\n",
        "    print(\"Training complete!\")\n",
        "    return train_losses, val_losses, train_accs, val_accs"
      ],
      "metadata": {
        "id": "qtg9Ou58UVGs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision.models import (\n",
        "    resnet50, ResNet50_Weights,\n",
        "    resnet34, ResNet34_Weights,\n",
        "    efficientnet_b0, EfficientNet_B0_Weights,\n",
        "    efficientnet_b3, EfficientNet_B3_Weights,\n",
        "    vgg16, VGG16_Weights,\n",
        "    densenet121, DenseNet121_Weights,\n",
        "    mobilenet_v2, MobileNet_V2_Weights,\n",
        "    inception_v3, Inception_V3_Weights\n",
        ")\n",
        "\n",
        "# Set device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Select the model\n",
        "selected_model_name = \"EfficientNet-B0\"  # Change this to train other models\n",
        "\n",
        "# Define models\n",
        "models_list = {\n",
        "    \"ResNet-50\": resnet50(weights=ResNet50_Weights.IMAGENET1K_V1),\n",
        "    \"ResNet-34\": resnet34(weights=ResNet34_Weights.IMAGENET1K_V1),\n",
        "    \"EfficientNet-B0\": efficientnet_b0(weights=EfficientNet_B0_Weights.IMAGENET1K_V1),\n",
        "    \"EfficientNet-B3\": efficientnet_b3(weights=EfficientNet_B3_Weights.IMAGENET1K_V1),\n",
        "    \"VGG16\": vgg16(weights=VGG16_Weights.IMAGENET1K_V1),\n",
        "    \"DenseNet-121\": densenet121(weights=DenseNet121_Weights.IMAGENET1K_V1),\n",
        "    \"MobileNet-V2\": mobilenet_v2(weights=MobileNet_V2_Weights.IMAGENET1K_V1),\n",
        "    \"Inception-V3\": inception_v3(weights=Inception_V3_Weights.IMAGENET1K_V1)\n",
        "}\n",
        "\n",
        "# Get the selected model\n",
        "model = models_list[selected_model_name]\n",
        "print(f\"\\nTraining {selected_model_name}...\\n\")\n",
        "\n",
        "# Adjust the final layer for 7 classes based on the model type\n",
        "if \"resnet\" in selected_model_name.lower():\n",
        "    num_features = model.fc.in_features\n",
        "    model.fc = nn.Linear(num_features, 7)\n",
        "elif \"efficientnet\" in selected_model_name.lower():\n",
        "    num_features = model.classifier[1].in_features if hasattr(model.classifier, \"__getitem__\") else model.classifier.in_features\n",
        "    model.classifier = nn.Linear(num_features, 7)\n",
        "elif \"densenet\" in selected_model_name.lower():\n",
        "    num_features = model.classifier.in_features\n",
        "    model.classifier = nn.Linear(num_features, 7)\n",
        "elif \"vgg\" in selected_model_name.lower():\n",
        "    num_features = model.classifier[6].in_features\n",
        "    model.classifier[6] = nn.Linear(num_features, 7)\n",
        "elif \"mobilenet\" in selected_model_name.lower():\n",
        "    num_features = model.classifier[1].in_features if hasattr(model.classifier, \"__getitem__\") else model.classifier.in_features\n",
        "    model.classifier = nn.Linear(num_features, 7)\n",
        "elif \"inception\" in selected_model_name.lower():\n",
        "    num_features = model.fc.in_features\n",
        "    model.fc = nn.Linear(num_features, 7)\n",
        "    if model.aux_logits:  # Inception has an auxiliary classifier\n",
        "        num_features_aux = model.AuxLogits.fc.in_features\n",
        "        model.AuxLogits.fc = nn.Linear(num_features_aux, 7)\n",
        "\n",
        "# Move model to the device (CPU/GPU)\n",
        "model = model.to(device)\n",
        "model.train()  # Ensure the model is in training mode\n",
        "\n",
        "# Define Loss Function and Optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001, weight_decay=1e-4)\n",
        "\n",
        "# Learning rate scheduler\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3, verbose=True)\n",
        "\n",
        "# Train the model\n",
        "train_losses, val_losses, train_accs, val_accs = train_model(\n",
        "    model=model,\n",
        "    model_name=selected_model_name,\n",
        "    criterion=criterion,\n",
        "    optimizer=optimizer,\n",
        "    train_loader=train_loader,\n",
        "    val_loader=val_loader,\n",
        "    device=device,\n",
        "    num_epochs=25,\n",
        "    patience=5,\n",
        "    scheduler=scheduler\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZBiHdRnAVDlU",
        "outputId": "3a2c71ed-29c4-4b33-d340-869518cb6167"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
            "100%|██████████| 97.8M/97.8M [00:00<00:00, 172MB/s]\n",
            "Downloading: \"https://download.pytorch.org/models/resnet34-b627a593.pth\" to /root/.cache/torch/hub/checkpoints/resnet34-b627a593.pth\n",
            "100%|██████████| 83.3M/83.3M [00:00<00:00, 173MB/s]\n",
            "Downloading: \"https://download.pytorch.org/models/efficientnet_b0_rwightman-7f5810bc.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b0_rwightman-7f5810bc.pth\n",
            "100%|██████████| 20.5M/20.5M [00:00<00:00, 124MB/s] \n",
            "Downloading: \"https://download.pytorch.org/models/efficientnet_b3_rwightman-b3899882.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b3_rwightman-b3899882.pth\n",
            "100%|██████████| 47.2M/47.2M [00:00<00:00, 146MB/s]\n",
            "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n",
            "100%|██████████| 528M/528M [00:07<00:00, 69.3MB/s]\n",
            "Downloading: \"https://download.pytorch.org/models/densenet121-a639ec97.pth\" to /root/.cache/torch/hub/checkpoints/densenet121-a639ec97.pth\n",
            "100%|██████████| 30.8M/30.8M [00:00<00:00, 129MB/s]\n",
            "Downloading: \"https://download.pytorch.org/models/mobilenet_v2-b0353104.pth\" to /root/.cache/torch/hub/checkpoints/mobilenet_v2-b0353104.pth\n",
            "100%|██████████| 13.6M/13.6M [00:00<00:00, 116MB/s] \n",
            "Downloading: \"https://download.pytorch.org/models/inception_v3_google-0cc3c7bd.pth\" to /root/.cache/torch/hub/checkpoints/inception_v3_google-0cc3c7bd.pth\n",
            "100%|██████████| 104M/104M [00:00<00:00, 162MB/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training EfficientNet-B0...\n",
            "\n",
            "Starting training...\n",
            "\n",
            "Epoch 1/25 started...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 0/455: Loss = 1.9868\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 10/455: Loss = 1.8429\n",
            "Batch 20/455: Loss = 1.7864\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 30/455: Loss = 1.6702\n",
            "Batch 40/455: Loss = 1.5498\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 50/455: Loss = 1.3687\n",
            "Batch 60/455: Loss = 1.2535\n",
            "Batch 70/455: Loss = 1.4229\n",
            "Batch 80/455: Loss = 1.3509\n",
            "Batch 90/455: Loss = 1.0045\n",
            "Batch 100/455: Loss = 0.9921\n",
            "Batch 110/455: Loss = 1.0148\n",
            "Batch 120/455: Loss = 1.3042\n",
            "Batch 130/455: Loss = 0.8123\n",
            "Batch 140/455: Loss = 0.7288\n",
            "Batch 150/455: Loss = 0.8070\n",
            "Batch 160/455: Loss = 0.8827\n",
            "Skipping corrupted image: /content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/paper/paper 2273.jpg - cannot identify image file <_io.BufferedReader name='/content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/paper/paper 2273.jpg'>\n",
            "Batch 170/455: Loss = 0.7620\n",
            "Batch 180/455: Loss = 0.9506\n",
            "Batch 190/455: Loss = 0.7264\n",
            "Batch 200/455: Loss = 0.8232\n",
            "Batch 210/455: Loss = 0.9330\n",
            "Batch 220/455: Loss = 0.7623\n",
            "Batch 230/455: Loss = 0.4776\n",
            "Batch 240/455: Loss = 0.5738\n",
            "Batch 250/455: Loss = 0.5167\n",
            "Batch 260/455: Loss = 0.6032\n",
            "Batch 270/455: Loss = 0.5423\n",
            "Batch 280/455: Loss = 0.5599\n",
            "Batch 290/455: Loss = 0.4675\n",
            "Batch 300/455: Loss = 0.5490\n",
            "Batch 310/455: Loss = 0.5171\n",
            "Skipping corrupted image: /content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/e-waste/e-waste 1719.jpg - cannot identify image file <_io.BufferedReader name='/content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/e-waste/e-waste 1719.jpg'>\n",
            "Batch 320/455: Loss = 0.6790\n",
            "Batch 330/455: Loss = 0.6912\n",
            "Batch 340/455: Loss = 0.5133\n",
            "Batch 350/455: Loss = 0.6679\n",
            "Batch 360/455: Loss = 0.4495\n",
            "Batch 370/455: Loss = 0.6070\n",
            "Batch 380/455: Loss = 0.5133\n",
            "Batch 390/455: Loss = 0.8124\n",
            "Batch 400/455: Loss = 0.5321\n",
            "Skipping corrupted image: /content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/cardboard/cardboard 1075.jpg - cannot identify image file <_io.BufferedReader name='/content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/cardboard/cardboard 1075.jpg'>\n",
            "Batch 410/455: Loss = 0.4676\n",
            "Batch 420/455: Loss = 0.8075\n",
            "Batch 430/455: Loss = 0.4874\n",
            "Batch 440/455: Loss = 0.5690\n",
            "Batch 450/455: Loss = 0.6356\n",
            "Training phase completed. Starting validation...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/25] completed.\n",
            "Train Loss: 0.8203 | Train Acc: 73.69%\n",
            "Val Loss: 0.3701 | Val Acc: 88.11%\n",
            "Precision: 88.45% | Recall: 87.51% | F1-score: 87.84%\n",
            "New best model saved at /content/drive/MyDrive/Waste Classification using Transfer Learning/Saved Models/EfficientNet-B0/Model_EfficientNetB0.pth!\n",
            "\n",
            "Epoch 2/25 started...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 0/455: Loss = 0.2288\n",
            "Batch 10/455: Loss = 0.3375\n",
            "Batch 20/455: Loss = 0.5164\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 30/455: Loss = 0.3192\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 40/455: Loss = 0.6134\n",
            "Batch 50/455: Loss = 0.4495\n",
            "Batch 60/455: Loss = 0.3597\n",
            "Batch 70/455: Loss = 0.4328\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 80/455: Loss = 0.3826\n",
            "Batch 90/455: Loss = 0.3662\n",
            "Batch 100/455: Loss = 0.5822\n",
            "Batch 110/455: Loss = 0.2356\n",
            "Skipping corrupted image: /content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/cardboard/cardboard 1075.jpg - cannot identify image file <_io.BufferedReader name='/content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/cardboard/cardboard 1075.jpg'>\n",
            "Batch 120/455: Loss = 0.2418\n",
            "Batch 130/455: Loss = 0.3379\n",
            "Batch 140/455: Loss = 0.2337\n",
            "Batch 150/455: Loss = 0.3541\n",
            "Skipping corrupted image: /content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/paper/paper 2273.jpg - cannot identify image file <_io.BufferedReader name='/content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/paper/paper 2273.jpg'>\n",
            "Batch 160/455: Loss = 0.4503\n",
            "Batch 170/455: Loss = 0.3666\n",
            "Batch 180/455: Loss = 0.4717\n",
            "Batch 190/455: Loss = 0.2795\n",
            "Batch 200/455: Loss = 0.5863\n",
            "Batch 210/455: Loss = 0.6079\n",
            "Batch 220/455: Loss = 0.7007\n",
            "Batch 230/455: Loss = 0.3124\n",
            "Batch 240/455: Loss = 0.7872\n",
            "Batch 250/455: Loss = 0.3457\n",
            "Batch 260/455: Loss = 0.4312\n",
            "Batch 270/455: Loss = 0.3365\n",
            "Batch 280/455: Loss = 0.3789\n",
            "Batch 290/455: Loss = 0.5321\n",
            "Batch 300/455: Loss = 0.5021\n",
            "Batch 310/455: Loss = 0.3818\n",
            "Batch 320/455: Loss = 0.2974\n",
            "Batch 330/455: Loss = 0.2019\n",
            "Batch 340/455: Loss = 0.4243\n",
            "Batch 350/455: Loss = 0.2147\n",
            "Batch 360/455: Loss = 0.2442\n",
            "Batch 370/455: Loss = 0.5303\n",
            "Batch 380/455: Loss = 0.2475\n",
            "Batch 390/455: Loss = 0.3801\n",
            "Batch 400/455: Loss = 0.7406\n",
            "Batch 410/455: Loss = 0.2410\n",
            "Skipping corrupted image: /content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/e-waste/e-waste 1719.jpg - cannot identify image file <_io.BufferedReader name='/content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/e-waste/e-waste 1719.jpg'>\n",
            "Batch 420/455: Loss = 0.4593\n",
            "Batch 430/455: Loss = 0.2761\n",
            "Batch 440/455: Loss = 0.3164\n",
            "Batch 450/455: Loss = 0.4252\n",
            "Training phase completed. Starting validation...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [2/25] completed.\n",
            "Train Loss: 0.3821 | Train Acc: 87.31%\n",
            "Val Loss: 0.3060 | Val Acc: 90.51%\n",
            "Precision: 90.61% | Recall: 90.06% | F1-score: 90.28%\n",
            "New best model saved at /content/drive/MyDrive/Waste Classification using Transfer Learning/Saved Models/EfficientNet-B0/Model_EfficientNetB0.pth!\n",
            "\n",
            "Epoch 3/25 started...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 0/455: Loss = 0.0709\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 10/455: Loss = 0.2834\n",
            "Batch 20/455: Loss = 0.1729\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 30/455: Loss = 0.2359\n",
            "Batch 40/455: Loss = 0.1584\n",
            "Batch 50/455: Loss = 0.3278\n",
            "Batch 60/455: Loss = 0.3441\n",
            "Skipping corrupted image: /content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/e-waste/e-waste 1719.jpg - cannot identify image file <_io.BufferedReader name='/content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/e-waste/e-waste 1719.jpg'>\n",
            "Batch 70/455: Loss = 0.2037\n",
            "Batch 80/455: Loss = 0.4760\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 90/455: Loss = 0.3291\n",
            "Batch 100/455: Loss = 0.3152\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 110/455: Loss = 0.1963\n",
            "Batch 120/455: Loss = 0.1632\n",
            "Batch 130/455: Loss = 0.3266\n",
            "Batch 140/455: Loss = 0.3276\n",
            "Batch 150/455: Loss = 0.2750\n",
            "Batch 160/455: Loss = 0.4173\n",
            "Batch 170/455: Loss = 0.1771\n",
            "Batch 180/455: Loss = 0.3888\n",
            "Batch 190/455: Loss = 0.1841\n",
            "Batch 200/455: Loss = 0.4446\n",
            "Batch 210/455: Loss = 0.1621\n",
            "Batch 220/455: Loss = 0.2291\n",
            "Batch 230/455: Loss = 0.3866\n",
            "Batch 240/455: Loss = 0.3639\n",
            "Batch 250/455: Loss = 0.2091\n",
            "Batch 260/455: Loss = 0.1678\n",
            "Batch 270/455: Loss = 0.3100\n",
            "Batch 280/455: Loss = 0.3721\n",
            "Batch 290/455: Loss = 0.4049\n",
            "Skipping corrupted image: /content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/paper/paper 2273.jpg - cannot identify image file <_io.BufferedReader name='/content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/paper/paper 2273.jpg'>\n",
            "Batch 300/455: Loss = 0.4030\n",
            "Skipping corrupted image: /content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/cardboard/cardboard 1075.jpg - cannot identify image file <_io.BufferedReader name='/content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/cardboard/cardboard 1075.jpg'>\n",
            "Batch 310/455: Loss = 0.1194\n",
            "Batch 320/455: Loss = 0.1366\n",
            "Batch 330/455: Loss = 0.0799\n",
            "Batch 340/455: Loss = 0.0868\n",
            "Batch 350/455: Loss = 0.2359\n",
            "Batch 360/455: Loss = 0.2116\n",
            "Batch 370/455: Loss = 0.2956\n",
            "Batch 380/455: Loss = 0.1457\n",
            "Batch 390/455: Loss = 0.4908\n",
            "Batch 400/455: Loss = 0.2283\n",
            "Batch 410/455: Loss = 0.4329\n",
            "Batch 420/455: Loss = 0.4075\n",
            "Batch 430/455: Loss = 0.2479\n",
            "Batch 440/455: Loss = 0.1861\n",
            "Batch 450/455: Loss = 0.1465\n",
            "Training phase completed. Starting validation...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [3/25] completed.\n",
            "Train Loss: 0.2686 | Train Acc: 91.17%\n",
            "Val Loss: 0.2748 | Val Acc: 91.07%\n",
            "Precision: 91.40% | Recall: 90.70% | F1-score: 90.99%\n",
            "New best model saved at /content/drive/MyDrive/Waste Classification using Transfer Learning/Saved Models/EfficientNet-B0/Model_EfficientNetB0.pth!\n",
            "\n",
            "Epoch 4/25 started...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 0/455: Loss = 0.1635\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 10/455: Loss = 0.4556\n",
            "Batch 20/455: Loss = 0.0653\n",
            "Skipping corrupted image: /content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/e-waste/e-waste 1719.jpg - cannot identify image file <_io.BufferedReader name='/content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/e-waste/e-waste 1719.jpg'>\n",
            "Batch 30/455: Loss = 0.0456\n",
            "Batch 40/455: Loss = 0.3675\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 50/455: Loss = 0.0994\n",
            "Batch 60/455: Loss = 0.2533\n",
            "Batch 70/455: Loss = 0.1511\n",
            "Batch 80/455: Loss = 0.4951\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 90/455: Loss = 0.1793\n",
            "Batch 100/455: Loss = 0.1716\n",
            "Batch 110/455: Loss = 0.2508\n",
            "Batch 120/455: Loss = 0.1976\n",
            "Batch 130/455: Loss = 0.2905\n",
            "Batch 140/455: Loss = 0.1352\n",
            "Batch 150/455: Loss = 0.1297\n",
            "Batch 160/455: Loss = 0.1535\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 170/455: Loss = 0.2877\n",
            "Batch 180/455: Loss = 0.1275\n",
            "Skipping corrupted image: /content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/cardboard/cardboard 1075.jpg - cannot identify image file <_io.BufferedReader name='/content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/cardboard/cardboard 1075.jpg'>\n",
            "Batch 190/455: Loss = 0.3307\n",
            "Batch 200/455: Loss = 0.0420\n",
            "Batch 210/455: Loss = 0.2836\n",
            "Batch 220/455: Loss = 0.1657\n",
            "Batch 230/455: Loss = 0.0963\n",
            "Batch 240/455: Loss = 0.2583\n",
            "Batch 250/455: Loss = 0.2430\n",
            "Batch 260/455: Loss = 0.4380\n",
            "Batch 270/455: Loss = 0.1685\n",
            "Batch 280/455: Loss = 0.1792\n",
            "Batch 290/455: Loss = 0.1766\n",
            "Batch 300/455: Loss = 0.1441\n",
            "Batch 310/455: Loss = 0.1626\n",
            "Batch 320/455: Loss = 0.1707\n",
            "Batch 330/455: Loss = 0.1260\n",
            "Skipping corrupted image: /content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/paper/paper 2273.jpg - cannot identify image file <_io.BufferedReader name='/content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/paper/paper 2273.jpg'>\n",
            "Batch 340/455: Loss = 0.1270\n",
            "Batch 350/455: Loss = 0.1650\n",
            "Batch 360/455: Loss = 0.1426\n",
            "Batch 370/455: Loss = 0.1929\n",
            "Batch 380/455: Loss = 0.2211\n",
            "Batch 390/455: Loss = 0.5537\n",
            "Batch 400/455: Loss = 0.2232\n",
            "Batch 410/455: Loss = 0.1052\n",
            "Batch 420/455: Loss = 0.1755\n",
            "Batch 430/455: Loss = 0.2292\n",
            "Batch 440/455: Loss = 0.1206\n",
            "Batch 450/455: Loss = 0.1210\n",
            "Training phase completed. Starting validation...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [4/25] completed.\n",
            "Train Loss: 0.2029 | Train Acc: 93.24%\n",
            "Val Loss: 0.2374 | Val Acc: 92.79%\n",
            "Precision: 92.83% | Recall: 92.72% | F1-score: 92.74%\n",
            "New best model saved at /content/drive/MyDrive/Waste Classification using Transfer Learning/Saved Models/EfficientNet-B0/Model_EfficientNetB0.pth!\n",
            "\n",
            "Epoch 5/25 started...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 0/455: Loss = 0.2404\n",
            "Skipping corrupted image: /content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/paper/paper 2273.jpg - cannot identify image file <_io.BufferedReader name='/content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/paper/paper 2273.jpg'>\n",
            "Batch 10/455: Loss = 0.0926\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 20/455: Loss = 0.1285\n",
            "Batch 30/455: Loss = 0.1257\n",
            "Batch 40/455: Loss = 0.0365\n",
            "Batch 50/455: Loss = 0.1855\n",
            "Batch 60/455: Loss = 0.1414\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 70/455: Loss = 0.0773\n",
            "Skipping corrupted image: /content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/cardboard/cardboard 1075.jpg - cannot identify image file <_io.BufferedReader name='/content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/cardboard/cardboard 1075.jpg'>\n",
            "Batch 80/455: Loss = 0.0599\n",
            "Batch 90/455: Loss = 0.3210\n",
            "Batch 100/455: Loss = 0.1757\n",
            "Batch 110/455: Loss = 0.2078\n",
            "Skipping corrupted image: /content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/e-waste/e-waste 1719.jpg - cannot identify image file <_io.BufferedReader name='/content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/e-waste/e-waste 1719.jpg'>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 120/455: Loss = 0.1282\n",
            "Batch 130/455: Loss = 0.1047\n",
            "Batch 140/455: Loss = 0.1996\n",
            "Batch 150/455: Loss = 0.0627\n",
            "Batch 160/455: Loss = 0.2392\n",
            "Batch 170/455: Loss = 0.1182\n",
            "Batch 180/455: Loss = 0.0740\n",
            "Batch 190/455: Loss = 0.2024\n",
            "Batch 200/455: Loss = 0.1755\n",
            "Batch 210/455: Loss = 0.0657\n",
            "Batch 220/455: Loss = 0.2155\n",
            "Batch 230/455: Loss = 0.1449\n",
            "Batch 240/455: Loss = 0.2725\n",
            "Batch 250/455: Loss = 0.3075\n",
            "Batch 260/455: Loss = 0.0598\n",
            "Batch 270/455: Loss = 0.0670\n",
            "Batch 280/455: Loss = 0.0851\n",
            "Batch 290/455: Loss = 0.1412\n",
            "Batch 300/455: Loss = 0.3338\n",
            "Batch 310/455: Loss = 0.1643\n",
            "Batch 320/455: Loss = 0.2561\n",
            "Batch 330/455: Loss = 0.2068\n",
            "Batch 340/455: Loss = 0.1257\n",
            "Batch 350/455: Loss = 0.1175\n",
            "Batch 360/455: Loss = 0.1982\n",
            "Batch 370/455: Loss = 0.1035\n",
            "Batch 380/455: Loss = 0.1251\n",
            "Batch 390/455: Loss = 0.3295\n",
            "Batch 400/455: Loss = 0.3561\n",
            "Batch 410/455: Loss = 0.0691\n",
            "Batch 420/455: Loss = 0.0814\n",
            "Batch 430/455: Loss = 0.1188\n",
            "Batch 440/455: Loss = 0.2054\n",
            "Batch 450/455: Loss = 0.1325\n",
            "Training phase completed. Starting validation...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [5/25] completed.\n",
            "Train Loss: 0.1618 | Train Acc: 94.68%\n",
            "Val Loss: 0.2566 | Val Acc: 92.61%\n",
            "Precision: 92.86% | Recall: 92.41% | F1-score: 92.57%\n",
            "Checkpoint saved at /content/drive/MyDrive/Waste Classification using Transfer Learning/Saved Models/EfficientNet-B0/checkpoint_epoch_5.pth!\n",
            "\n",
            "Epoch 6/25 started...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 0/455: Loss = 0.0764\n",
            "Batch 10/455: Loss = 0.0331\n",
            "Batch 20/455: Loss = 0.0437\n",
            "Batch 30/455: Loss = 0.0555\n",
            "Batch 40/455: Loss = 0.1236\n",
            "Batch 50/455: Loss = 0.2348\n",
            "Batch 60/455: Loss = 0.1163\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 70/455: Loss = 0.1223\n",
            "Batch 80/455: Loss = 0.0464\n",
            "Batch 90/455: Loss = 0.0444\n",
            "Batch 100/455: Loss = 0.1335\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 110/455: Loss = 0.0331\n",
            "Batch 120/455: Loss = 0.2973\n",
            "Batch 130/455: Loss = 0.0399\n",
            "Skipping corrupted image: /content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/cardboard/cardboard 1075.jpg - cannot identify image file <_io.BufferedReader name='/content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/cardboard/cardboard 1075.jpg'>\n",
            "Batch 140/455: Loss = 0.0815\n",
            "Batch 150/455: Loss = 0.1677\n",
            "Batch 160/455: Loss = 0.1759\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 170/455: Loss = 0.0824\n",
            "Batch 180/455: Loss = 0.1098\n",
            "Batch 190/455: Loss = 0.2272\n",
            "Batch 200/455: Loss = 0.2268\n",
            "Batch 210/455: Loss = 0.0570\n",
            "Batch 220/455: Loss = 0.0862\n",
            "Skipping corrupted image: /content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/e-waste/e-waste 1719.jpg - cannot identify image file <_io.BufferedReader name='/content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/e-waste/e-waste 1719.jpg'>\n",
            "Batch 230/455: Loss = 0.0594\n",
            "Batch 240/455: Loss = 0.0249\n",
            "Batch 250/455: Loss = 0.1127\n",
            "Batch 260/455: Loss = 0.1176\n",
            "Batch 270/455: Loss = 0.1875\n",
            "Batch 280/455: Loss = 0.1301\n",
            "Batch 290/455: Loss = 0.1242\n",
            "Batch 300/455: Loss = 0.0494\n",
            "Batch 310/455: Loss = 0.0968\n",
            "Batch 320/455: Loss = 0.2324\n",
            "Batch 330/455: Loss = 0.0851\n",
            "Batch 340/455: Loss = 0.1716\n",
            "Batch 350/455: Loss = 0.2492\n",
            "Batch 360/455: Loss = 0.1667\n",
            "Batch 370/455: Loss = 0.1118\n",
            "Batch 380/455: Loss = 0.1237\n",
            "Batch 390/455: Loss = 0.3142\n",
            "Batch 400/455: Loss = 0.1046\n",
            "Batch 410/455: Loss = 0.0864\n",
            "Skipping corrupted image: /content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/paper/paper 2273.jpg - cannot identify image file <_io.BufferedReader name='/content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/paper/paper 2273.jpg'>\n",
            "Batch 420/455: Loss = 0.0467\n",
            "Batch 430/455: Loss = 0.0502\n",
            "Batch 440/455: Loss = 0.0607\n",
            "Batch 450/455: Loss = 0.1703\n",
            "Training phase completed. Starting validation...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [6/25] completed.\n",
            "Train Loss: 0.1311 | Train Acc: 95.67%\n",
            "Val Loss: 0.2600 | Val Acc: 92.48%\n",
            "Precision: 92.78% | Recall: 92.16% | F1-score: 92.40%\n",
            "\n",
            "Epoch 7/25 started...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 0/455: Loss = 0.0929\n",
            "Batch 10/455: Loss = 0.1899\n",
            "Skipping corrupted image: /content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/paper/paper 2273.jpg - cannot identify image file <_io.BufferedReader name='/content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/paper/paper 2273.jpg'>\n",
            "Batch 20/455: Loss = 0.2353\n",
            "Batch 30/455: Loss = 0.1172\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 40/455: Loss = 0.0655\n",
            "Batch 50/455: Loss = 0.0869\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 60/455: Loss = 0.1954\n",
            "Batch 70/455: Loss = 0.0414\n",
            "Batch 80/455: Loss = 0.0517\n",
            "Batch 90/455: Loss = 0.0285\n",
            "Batch 100/455: Loss = 0.0464\n",
            "Batch 110/455: Loss = 0.1122\n",
            "Batch 120/455: Loss = 0.0317\n",
            "Batch 130/455: Loss = 0.3701\n",
            "Batch 140/455: Loss = 0.0517\n",
            "Batch 150/455: Loss = 0.1505\n",
            "Batch 160/455: Loss = 0.0312\n",
            "Batch 170/455: Loss = 0.0462\n",
            "Batch 180/455: Loss = 0.0278\n",
            "Batch 190/455: Loss = 0.1219\n",
            "Batch 200/455: Loss = 0.1814\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 210/455: Loss = 0.1379\n",
            "Batch 220/455: Loss = 0.0182\n",
            "Batch 230/455: Loss = 0.0565\n",
            "Batch 240/455: Loss = 0.0765\n",
            "Batch 250/455: Loss = 0.0735\n",
            "Skipping corrupted image: /content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/e-waste/e-waste 1719.jpg - cannot identify image file <_io.BufferedReader name='/content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/e-waste/e-waste 1719.jpg'>\n",
            "Batch 260/455: Loss = 0.1158\n",
            "Batch 270/455: Loss = 0.0210\n",
            "Batch 280/455: Loss = 0.0120\n",
            "Batch 290/455: Loss = 0.2421\n",
            "Batch 300/455: Loss = 0.1289\n",
            "Batch 310/455: Loss = 0.1054\n",
            "Batch 320/455: Loss = 0.0228\n",
            "Batch 330/455: Loss = 0.2265\n",
            "Batch 340/455: Loss = 0.2229\n",
            "Batch 350/455: Loss = 0.1267\n",
            "Batch 360/455: Loss = 0.0633\n",
            "Batch 370/455: Loss = 0.2236\n",
            "Batch 380/455: Loss = 0.0258\n",
            "Batch 390/455: Loss = 0.0565\n",
            "Batch 400/455: Loss = 0.0465\n",
            "Batch 410/455: Loss = 0.0108\n",
            "Batch 420/455: Loss = 0.1819\n",
            "Batch 430/455: Loss = 0.1053\n",
            "Skipping corrupted image: /content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/cardboard/cardboard 1075.jpg - cannot identify image file <_io.BufferedReader name='/content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/cardboard/cardboard 1075.jpg'>\n",
            "Batch 440/455: Loss = 0.0880\n",
            "Batch 450/455: Loss = 0.0897\n",
            "Training phase completed. Starting validation...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [7/25] completed.\n",
            "Train Loss: 0.1087 | Train Acc: 96.41%\n",
            "Val Loss: 0.2637 | Val Acc: 92.36%\n",
            "Precision: 92.69% | Recall: 91.98% | F1-score: 92.26%\n",
            "\n",
            "Epoch 8/25 started...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 0/455: Loss = 0.0110\n",
            "Skipping corrupted image: /content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/paper/paper 2273.jpg - cannot identify image file <_io.BufferedReader name='/content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/paper/paper 2273.jpg'>\n",
            "Batch 10/455: Loss = 0.0484\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 20/455: Loss = 0.1127\n",
            "Batch 30/455: Loss = 0.0329\n",
            "Batch 40/455: Loss = 0.0621\n",
            "Batch 50/455: Loss = 0.0838\n",
            "Batch 60/455: Loss = 0.2835\n",
            "Batch 70/455: Loss = 0.0464\n",
            "Batch 80/455: Loss = 0.1195\n",
            "Batch 90/455: Loss = 0.0248\n",
            "Batch 100/455: Loss = 0.0931\n",
            "Batch 110/455: Loss = 0.0153\n",
            "Skipping corrupted image: /content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/cardboard/cardboard 1075.jpg - cannot identify image file <_io.BufferedReader name='/content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/cardboard/cardboard 1075.jpg'>\n",
            "Batch 120/455: Loss = 0.0155\n",
            "Batch 130/455: Loss = 0.4457\n",
            "Batch 140/455: Loss = 0.0784\n",
            "Batch 150/455: Loss = 0.2783\n",
            "Batch 160/455: Loss = 0.0506\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 170/455: Loss = 0.1278\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 180/455: Loss = 0.1050\n",
            "Batch 190/455: Loss = 0.1309\n",
            "Batch 200/455: Loss = 0.0352\n",
            "Batch 210/455: Loss = 0.0541\n",
            "Batch 220/455: Loss = 0.0592\n",
            "Batch 230/455: Loss = 0.0660\n",
            "Batch 240/455: Loss = 0.1822\n",
            "Batch 250/455: Loss = 0.0310\n",
            "Batch 260/455: Loss = 0.0921\n",
            "Batch 270/455: Loss = 0.1451\n",
            "Batch 280/455: Loss = 0.0383\n",
            "Batch 290/455: Loss = 0.2165\n",
            "Batch 300/455: Loss = 0.0536\n",
            "Batch 310/455: Loss = 0.1052\n",
            "Batch 320/455: Loss = 0.0633\n",
            "Batch 330/455: Loss = 0.1105\n",
            "Batch 340/455: Loss = 0.0398\n",
            "Batch 350/455: Loss = 0.0180\n",
            "Batch 360/455: Loss = 0.1664\n",
            "Batch 370/455: Loss = 0.0169\n",
            "Batch 380/455: Loss = 0.0955\n",
            "Batch 390/455: Loss = 0.2158\n",
            "Batch 400/455: Loss = 0.0698\n",
            "Batch 410/455: Loss = 0.0412\n",
            "Skipping corrupted image: /content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/e-waste/e-waste 1719.jpg - cannot identify image file <_io.BufferedReader name='/content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/e-waste/e-waste 1719.jpg'>\n",
            "Batch 420/455: Loss = 0.0512\n",
            "Batch 430/455: Loss = 0.0928\n",
            "Batch 440/455: Loss = 0.1249\n",
            "Batch 450/455: Loss = 0.0183\n",
            "Training phase completed. Starting validation...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [8/25] completed.\n",
            "Train Loss: 0.1022 | Train Acc: 96.70%\n",
            "Val Loss: 0.2742 | Val Acc: 92.85%\n",
            "Precision: 93.24% | Recall: 92.52% | F1-score: 92.79%\n",
            "New best model saved at /content/drive/MyDrive/Waste Classification using Transfer Learning/Saved Models/EfficientNet-B0/Model_EfficientNetB0.pth!\n",
            "\n",
            "Epoch 9/25 started...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 0/455: Loss = 0.0669\n",
            "Batch 10/455: Loss = 0.0481\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 20/455: Loss = 0.0090\n",
            "Batch 30/455: Loss = 0.0357\n",
            "Skipping corrupted image: /content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/e-waste/e-waste 1719.jpg - cannot identify image file <_io.BufferedReader name='/content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/e-waste/e-waste 1719.jpg'>\n",
            "Batch 40/455: Loss = 0.1780\n",
            "Batch 50/455: Loss = 0.0737\n",
            "Batch 60/455: Loss = 0.0936\n",
            "Skipping corrupted image: /content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/paper/paper 2273.jpg - cannot identify image file <_io.BufferedReader name='/content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/paper/paper 2273.jpg'>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 70/455: Loss = 0.0906\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 80/455: Loss = 0.0553\n",
            "Batch 90/455: Loss = 0.1399\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 100/455: Loss = 0.1033\n",
            "Skipping corrupted image: /content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/cardboard/cardboard 1075.jpg - cannot identify image file <_io.BufferedReader name='/content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/cardboard/cardboard 1075.jpg'>\n",
            "Batch 110/455: Loss = 0.2820\n",
            "Batch 120/455: Loss = 0.2050\n",
            "Batch 130/455: Loss = 0.0953\n",
            "Batch 140/455: Loss = 0.0919\n",
            "Batch 150/455: Loss = 0.0928\n",
            "Batch 160/455: Loss = 0.0147\n",
            "Batch 170/455: Loss = 0.0543\n",
            "Batch 180/455: Loss = 0.0460\n",
            "Batch 190/455: Loss = 0.3849\n",
            "Batch 200/455: Loss = 0.0589\n",
            "Batch 210/455: Loss = 0.0371\n",
            "Batch 220/455: Loss = 0.0211\n",
            "Batch 230/455: Loss = 0.0458\n",
            "Batch 240/455: Loss = 0.0124\n",
            "Batch 250/455: Loss = 0.0639\n",
            "Batch 260/455: Loss = 0.0241\n",
            "Batch 270/455: Loss = 0.0710\n",
            "Batch 280/455: Loss = 0.2532\n",
            "Batch 290/455: Loss = 0.0209\n",
            "Batch 300/455: Loss = 0.0617\n",
            "Batch 310/455: Loss = 0.2137\n",
            "Batch 320/455: Loss = 0.0699\n",
            "Batch 330/455: Loss = 0.0429\n",
            "Batch 340/455: Loss = 0.1095\n",
            "Batch 350/455: Loss = 0.0722\n",
            "Batch 360/455: Loss = 0.1233\n",
            "Batch 370/455: Loss = 0.1568\n",
            "Batch 380/455: Loss = 0.1785\n",
            "Batch 390/455: Loss = 0.0479\n",
            "Batch 400/455: Loss = 0.1536\n",
            "Batch 410/455: Loss = 0.0070\n",
            "Batch 420/455: Loss = 0.0656\n",
            "Batch 430/455: Loss = 0.0980\n",
            "Batch 440/455: Loss = 0.0910\n",
            "Batch 450/455: Loss = 0.0078\n",
            "Training phase completed. Starting validation...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [9/25] completed.\n",
            "Train Loss: 0.0820 | Train Acc: 97.36%\n",
            "Val Loss: 0.2961 | Val Acc: 91.87%\n",
            "Precision: 92.20% | Recall: 91.51% | F1-score: 91.77%\n",
            "\n",
            "Epoch 10/25 started...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 0/455: Loss = 0.0819\n",
            "Batch 10/455: Loss = 0.0115\n",
            "Skipping corrupted image: /content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/cardboard/cardboard 1075.jpg - cannot identify image file <_io.BufferedReader name='/content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/cardboard/cardboard 1075.jpg'>\n",
            "Batch 20/455: Loss = 0.2306\n",
            "Batch 30/455: Loss = 0.0745\n",
            "Batch 40/455: Loss = 0.0666\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 50/455: Loss = 0.0967\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 60/455: Loss = 0.0401\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 70/455: Loss = 0.0266\n",
            "Batch 80/455: Loss = 0.0067\n",
            "Batch 90/455: Loss = 0.0218\n",
            "Batch 100/455: Loss = 0.1344\n",
            "Batch 110/455: Loss = 0.1133\n",
            "Batch 120/455: Loss = 0.0935\n",
            "Batch 130/455: Loss = 0.0082\n",
            "Batch 140/455: Loss = 0.0399\n",
            "Batch 150/455: Loss = 0.0760\n",
            "Batch 160/455: Loss = 0.1696\n",
            "Batch 170/455: Loss = 0.0526\n",
            "Batch 180/455: Loss = 0.0080\n",
            "Skipping corrupted image: /content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/e-waste/e-waste 1719.jpg - cannot identify image file <_io.BufferedReader name='/content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/e-waste/e-waste 1719.jpg'>\n",
            "Batch 190/455: Loss = 0.0687\n",
            "Batch 200/455: Loss = 0.0424\n",
            "Batch 210/455: Loss = 0.0358\n",
            "Batch 220/455: Loss = 0.1443\n",
            "Batch 230/455: Loss = 0.1008\n",
            "Batch 240/455: Loss = 0.0133\n",
            "Batch 250/455: Loss = 0.0165\n",
            "Batch 260/455: Loss = 0.0290\n",
            "Skipping corrupted image: /content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/paper/paper 2273.jpg - cannot identify image file <_io.BufferedReader name='/content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/paper/paper 2273.jpg'>\n",
            "Batch 270/455: Loss = 0.0535\n",
            "Batch 280/455: Loss = 0.0533\n",
            "Batch 290/455: Loss = 0.0513\n",
            "Batch 300/455: Loss = 0.0423\n",
            "Batch 310/455: Loss = 0.0274\n",
            "Batch 320/455: Loss = 0.0810\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 330/455: Loss = 0.0160\n",
            "Batch 340/455: Loss = 0.2073\n",
            "Batch 350/455: Loss = 0.0236\n",
            "Batch 360/455: Loss = 0.0094\n",
            "Batch 370/455: Loss = 0.0049\n",
            "Batch 380/455: Loss = 0.0806\n",
            "Batch 390/455: Loss = 0.1206\n",
            "Batch 400/455: Loss = 0.0703\n",
            "Batch 410/455: Loss = 0.1403\n",
            "Batch 420/455: Loss = 0.3311\n",
            "Batch 430/455: Loss = 0.0181\n",
            "Batch 440/455: Loss = 0.2121\n",
            "Batch 450/455: Loss = 0.1323\n",
            "Training phase completed. Starting validation...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/25] completed.\n",
            "Train Loss: 0.0752 | Train Acc: 97.48%\n",
            "Val Loss: 0.2840 | Val Acc: 92.85%\n",
            "Precision: 92.97% | Recall: 92.76% | F1-score: 92.81%\n",
            "Checkpoint saved at /content/drive/MyDrive/Waste Classification using Transfer Learning/Saved Models/EfficientNet-B0/checkpoint_epoch_10.pth!\n",
            "\n",
            "Epoch 11/25 started...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 0/455: Loss = 0.0446\n",
            "Batch 10/455: Loss = 0.0097\n",
            "Batch 20/455: Loss = 0.0325\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 30/455: Loss = 0.0793\n",
            "Batch 40/455: Loss = 0.0516\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 50/455: Loss = 0.1196\n",
            "Batch 60/455: Loss = 0.0460\n",
            "Batch 70/455: Loss = 0.0562\n",
            "Batch 80/455: Loss = 0.0223\n",
            "Batch 90/455: Loss = 0.0131\n",
            "Batch 100/455: Loss = 0.0777\n",
            "Batch 110/455: Loss = 0.0971\n",
            "Batch 120/455: Loss = 0.0640\n",
            "Batch 130/455: Loss = 0.1165\n",
            "Batch 140/455: Loss = 0.0428\n",
            "Batch 150/455: Loss = 0.0178\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 160/455: Loss = 0.0141\n",
            "Batch 170/455: Loss = 0.0597\n",
            "Batch 180/455: Loss = 0.0170\n",
            "Batch 190/455: Loss = 0.0167\n",
            "Batch 200/455: Loss = 0.2172\n",
            "Batch 210/455: Loss = 0.0017\n",
            "Batch 220/455: Loss = 0.0566\n",
            "Batch 230/455: Loss = 0.0254\n",
            "Batch 240/455: Loss = 0.0995\n",
            "Batch 250/455: Loss = 0.0920\n",
            "Batch 260/455: Loss = 0.0222\n",
            "Batch 270/455: Loss = 0.1272\n",
            "Skipping corrupted image: /content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/e-waste/e-waste 1719.jpg - cannot identify image file <_io.BufferedReader name='/content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/e-waste/e-waste 1719.jpg'>\n",
            "Batch 280/455: Loss = 0.0586\n",
            "Batch 290/455: Loss = 0.0419\n",
            "Batch 300/455: Loss = 0.0872\n",
            "Batch 310/455: Loss = 0.0378\n",
            "Batch 320/455: Loss = 0.0917\n",
            "Batch 330/455: Loss = 0.4074\n",
            "Skipping corrupted image: /content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/cardboard/cardboard 1075.jpg - cannot identify image file <_io.BufferedReader name='/content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/cardboard/cardboard 1075.jpg'>\n",
            "Batch 340/455: Loss = 0.0260\n",
            "Batch 350/455: Loss = 0.1603\n",
            "Batch 360/455: Loss = 0.0086\n",
            "Batch 370/455: Loss = 0.0252\n",
            "Batch 380/455: Loss = 0.0172\n",
            "Skipping corrupted image: /content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/paper/paper 2273.jpg - cannot identify image file <_io.BufferedReader name='/content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/paper/paper 2273.jpg'>\n",
            "Batch 390/455: Loss = 0.0303\n",
            "Batch 400/455: Loss = 0.0239\n",
            "Batch 410/455: Loss = 0.0710\n",
            "Batch 420/455: Loss = 0.0190\n",
            "Batch 430/455: Loss = 0.0189\n",
            "Batch 440/455: Loss = 0.0178\n",
            "Batch 450/455: Loss = 0.0882\n",
            "Training phase completed. Starting validation...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [11/25] completed.\n",
            "Train Loss: 0.0668 | Train Acc: 97.82%\n",
            "Val Loss: 0.3006 | Val Acc: 92.79%\n",
            "Precision: 92.88% | Recall: 92.67% | F1-score: 92.72%\n",
            "\n",
            "Epoch 12/25 started...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 0/455: Loss = 0.0351\n",
            "Batch 10/455: Loss = 0.0255\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 20/455: Loss = 0.0611\n",
            "Batch 30/455: Loss = 0.0096\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 40/455: Loss = 0.0509\n",
            "Batch 50/455: Loss = 0.0984\n",
            "Batch 60/455: Loss = 0.0417\n",
            "Batch 70/455: Loss = 0.0442\n",
            "Batch 80/455: Loss = 0.0147\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 90/455: Loss = 0.0077\n",
            "Batch 100/455: Loss = 0.1379\n",
            "Batch 110/455: Loss = 0.1586\n",
            "Skipping corrupted image: /content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/paper/paper 2273.jpg - cannot identify image file <_io.BufferedReader name='/content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/paper/paper 2273.jpg'>\n",
            "Batch 120/455: Loss = 0.0973\n",
            "Batch 130/455: Loss = 0.0235\n",
            "Batch 140/455: Loss = 0.0315\n",
            "Batch 150/455: Loss = 0.0564\n",
            "Batch 160/455: Loss = 0.0345\n",
            "Batch 170/455: Loss = 0.0242\n",
            "Batch 180/455: Loss = 0.0069\n",
            "Batch 190/455: Loss = 0.0249\n",
            "Batch 200/455: Loss = 0.0947\n",
            "Skipping corrupted image: /content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/cardboard/cardboard 1075.jpg - cannot identify image file <_io.BufferedReader name='/content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/cardboard/cardboard 1075.jpg'>\n",
            "Batch 210/455: Loss = 0.1335\n",
            "Batch 220/455: Loss = 0.0357\n",
            "Batch 230/455: Loss = 0.1131\n",
            "Batch 240/455: Loss = 0.2671\n",
            "Batch 250/455: Loss = 0.0072\n",
            "Batch 260/455: Loss = 0.1050\n",
            "Batch 270/455: Loss = 0.0353\n",
            "Batch 280/455: Loss = 0.0425\n",
            "Batch 290/455: Loss = 0.0021\n",
            "Batch 300/455: Loss = 0.1554\n",
            "Batch 310/455: Loss = 0.0950\n",
            "Batch 320/455: Loss = 0.0058\n",
            "Batch 330/455: Loss = 0.0661\n",
            "Batch 340/455: Loss = 0.0609\n",
            "Batch 350/455: Loss = 0.1100\n",
            "Skipping corrupted image: /content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/e-waste/e-waste 1719.jpg - cannot identify image file <_io.BufferedReader name='/content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/e-waste/e-waste 1719.jpg'>\n",
            "Batch 360/455: Loss = 0.0307\n",
            "Batch 370/455: Loss = 0.0179\n",
            "Batch 380/455: Loss = 0.0155\n",
            "Batch 390/455: Loss = 0.0235\n",
            "Batch 400/455: Loss = 0.0161\n",
            "Batch 410/455: Loss = 0.0173\n",
            "Batch 420/455: Loss = 0.0294\n",
            "Batch 430/455: Loss = 0.0750\n",
            "Batch 440/455: Loss = 0.0659\n",
            "Batch 450/455: Loss = 0.0145\n",
            "Training phase completed. Starting validation...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [12/25] completed.\n",
            "Train Loss: 0.0601 | Train Acc: 98.01%\n",
            "Val Loss: 0.2972 | Val Acc: 92.67%\n",
            "Precision: 92.97% | Recall: 92.31% | F1-score: 92.57%\n",
            "\n",
            "Epoch 13/25 started...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 0/455: Loss = 0.0188\n",
            "Batch 10/455: Loss = 0.0932\n",
            "Skipping corrupted image: /content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/e-waste/e-waste 1719.jpg - cannot identify image file <_io.BufferedReader name='/content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/e-waste/e-waste 1719.jpg'>\n",
            "Batch 20/455: Loss = 0.1995\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 30/455: Loss = 0.0094\n",
            "Batch 40/455: Loss = 0.0206\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 50/455: Loss = 0.1004\n",
            "Batch 60/455: Loss = 0.0134\n",
            "Batch 70/455: Loss = 0.0120\n",
            "Batch 80/455: Loss = 0.0290\n",
            "Batch 90/455: Loss = 0.0346\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 100/455: Loss = 0.0103\n",
            "Skipping corrupted image: /content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/paper/paper 2273.jpg - cannot identify image file <_io.BufferedReader name='/content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/paper/paper 2273.jpg'>\n",
            "Batch 110/455: Loss = 0.0957\n",
            "Batch 120/455: Loss = 0.0497\n",
            "Batch 130/455: Loss = 0.0663\n",
            "Batch 140/455: Loss = 0.0172\n",
            "Batch 150/455: Loss = 0.0261\n",
            "Batch 160/455: Loss = 0.0561\n",
            "Batch 170/455: Loss = 0.0129\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 180/455: Loss = 0.0753\n",
            "Batch 190/455: Loss = 0.0121\n",
            "Batch 200/455: Loss = 0.0183\n",
            "Batch 210/455: Loss = 0.0054\n",
            "Batch 220/455: Loss = 0.0282\n",
            "Batch 230/455: Loss = 0.0681\n",
            "Batch 240/455: Loss = 0.0231\n",
            "Batch 250/455: Loss = 0.0283\n",
            "Batch 260/455: Loss = 0.1648\n",
            "Batch 270/455: Loss = 0.0845\n",
            "Batch 280/455: Loss = 0.1051\n",
            "Batch 290/455: Loss = 0.0684\n",
            "Batch 300/455: Loss = 0.0934\n",
            "Batch 310/455: Loss = 0.0199\n",
            "Batch 320/455: Loss = 0.0409\n",
            "Batch 330/455: Loss = 0.0170\n",
            "Batch 340/455: Loss = 0.0202\n",
            "Batch 350/455: Loss = 0.1065\n",
            "Batch 360/455: Loss = 0.0196\n",
            "Batch 370/455: Loss = 0.0439\n",
            "Batch 380/455: Loss = 0.0094\n",
            "Batch 390/455: Loss = 0.1254\n",
            "Batch 400/455: Loss = 0.0445\n",
            "Batch 410/455: Loss = 0.2120\n",
            "Batch 420/455: Loss = 0.0393\n",
            "Batch 430/455: Loss = 0.0889\n",
            "Batch 440/455: Loss = 0.0609\n",
            "Skipping corrupted image: /content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/cardboard/cardboard 1075.jpg - cannot identify image file <_io.BufferedReader name='/content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/cardboard/cardboard 1075.jpg'>\n",
            "Batch 450/455: Loss = 0.0343\n",
            "Training phase completed. Starting validation...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [13/25] completed.\n",
            "Train Loss: 0.0548 | Train Acc: 98.25%\n",
            "Val Loss: 0.2805 | Val Acc: 93.41%\n",
            "Precision: 93.63% | Recall: 93.30% | F1-score: 93.44%\n",
            "New best model saved at /content/drive/MyDrive/Waste Classification using Transfer Learning/Saved Models/EfficientNet-B0/Model_EfficientNetB0.pth!\n",
            "\n",
            "Epoch 14/25 started...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 0/455: Loss = 0.0284\n",
            "Batch 10/455: Loss = 0.0397\n",
            "Batch 20/455: Loss = 0.0208\n",
            "Batch 30/455: Loss = 0.0129\n",
            "Batch 40/455: Loss = 0.1091\n",
            "Batch 50/455: Loss = 0.0661\n",
            "Skipping corrupted image: /content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/e-waste/e-waste 1719.jpg - cannot identify image file <_io.BufferedReader name='/content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/e-waste/e-waste 1719.jpg'>\n",
            "Batch 60/455: Loss = 0.0045\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 70/455: Loss = 0.0131\n",
            "Skipping corrupted image: /content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/paper/paper 2273.jpg - cannot identify image file <_io.BufferedReader name='/content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/paper/paper 2273.jpg'>\n",
            "Batch 80/455: Loss = 0.1744\n",
            "Batch 90/455: Loss = 0.0115\n",
            "Batch 100/455: Loss = 0.1543\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 110/455: Loss = 0.0084\n",
            "Batch 120/455: Loss = 0.0133\n",
            "Batch 130/455: Loss = 0.0569\n",
            "Batch 140/455: Loss = 0.0900\n",
            "Batch 150/455: Loss = 0.0580\n",
            "Batch 160/455: Loss = 0.0377\n",
            "Batch 170/455: Loss = 0.0210\n",
            "Batch 180/455: Loss = 0.1745\n",
            "Batch 190/455: Loss = 0.0601\n",
            "Batch 200/455: Loss = 0.0178\n",
            "Batch 210/455: Loss = 0.0122\n",
            "Batch 220/455: Loss = 0.0040\n",
            "Batch 230/455: Loss = 0.0228\n",
            "Batch 240/455: Loss = 0.0239\n",
            "Batch 250/455: Loss = 0.0758\n",
            "Batch 260/455: Loss = 0.0321\n",
            "Batch 270/455: Loss = 0.0251\n",
            "Skipping corrupted image: /content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/cardboard/cardboard 1075.jpg - cannot identify image file <_io.BufferedReader name='/content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/cardboard/cardboard 1075.jpg'>\n",
            "Batch 280/455: Loss = 0.0465\n",
            "Batch 290/455: Loss = 0.2140\n",
            "Batch 300/455: Loss = 0.0128\n",
            "Batch 310/455: Loss = 0.0343\n",
            "Batch 320/455: Loss = 0.1009\n",
            "Batch 330/455: Loss = 0.0116\n",
            "Batch 340/455: Loss = 0.0493\n",
            "Batch 350/455: Loss = 0.0154\n",
            "Batch 360/455: Loss = 0.0452\n",
            "Batch 370/455: Loss = 0.0093\n",
            "Batch 380/455: Loss = 0.0695\n",
            "Batch 390/455: Loss = 0.0093\n",
            "Batch 400/455: Loss = 0.0764\n",
            "Batch 410/455: Loss = 0.0571\n",
            "Batch 420/455: Loss = 0.1177\n",
            "Batch 430/455: Loss = 0.0722\n",
            "Batch 440/455: Loss = 0.0643\n",
            "Batch 450/455: Loss = 0.0187\n",
            "Training phase completed. Starting validation...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [14/25] completed.\n",
            "Train Loss: 0.0593 | Train Acc: 98.15%\n",
            "Val Loss: 0.2894 | Val Acc: 93.28%\n",
            "Precision: 93.55% | Recall: 93.17% | F1-score: 93.33%\n",
            "\n",
            "Epoch 15/25 started...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 0/455: Loss = 0.0215\n",
            "Batch 10/455: Loss = 0.0301\n",
            "Batch 20/455: Loss = 0.0046\n",
            "Batch 30/455: Loss = 0.0301\n",
            "Batch 40/455: Loss = 0.0668\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 50/455: Loss = 0.0157\n",
            "Batch 60/455: Loss = 0.0252\n",
            "Batch 70/455: Loss = 0.0073\n",
            "Batch 80/455: Loss = 0.1556\n",
            "Batch 90/455: Loss = 0.0287\n",
            "Batch 100/455: Loss = 0.0170\n",
            "Batch 110/455: Loss = 0.2427\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 120/455: Loss = 0.0673\n",
            "Batch 130/455: Loss = 0.1248\n",
            "Batch 140/455: Loss = 0.1880\n",
            "Batch 150/455: Loss = 0.1079\n",
            "Batch 160/455: Loss = 0.0650\n",
            "Batch 170/455: Loss = 0.0963\n",
            "Batch 180/455: Loss = 0.0514\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 190/455: Loss = 0.0229\n",
            "Batch 200/455: Loss = 0.0282\n",
            "Batch 210/455: Loss = 0.0385\n",
            "Batch 220/455: Loss = 0.0724\n",
            "Batch 230/455: Loss = 0.0078\n",
            "Batch 240/455: Loss = 0.0522\n",
            "Batch 250/455: Loss = 0.0058\n",
            "Batch 260/455: Loss = 0.0078\n",
            "Batch 270/455: Loss = 0.0100\n",
            "Batch 280/455: Loss = 0.0575\n",
            "Batch 290/455: Loss = 0.0053\n",
            "Batch 300/455: Loss = 0.0034\n",
            "Batch 310/455: Loss = 0.0075\n",
            "Batch 320/455: Loss = 0.0159\n",
            "Batch 330/455: Loss = 0.2235\n",
            "Batch 340/455: Loss = 0.0591\n",
            "Batch 350/455: Loss = 0.0096\n",
            "Batch 360/455: Loss = 0.1437\n",
            "Skipping corrupted image: /content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/e-waste/e-waste 1719.jpg - cannot identify image file <_io.BufferedReader name='/content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/e-waste/e-waste 1719.jpg'>\n",
            "Batch 370/455: Loss = 0.0213\n",
            "Batch 380/455: Loss = 0.0664\n",
            "Batch 390/455: Loss = 0.0043\n",
            "Skipping corrupted image: /content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/paper/paper 2273.jpg - cannot identify image file <_io.BufferedReader name='/content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/paper/paper 2273.jpg'>\n",
            "Batch 400/455: Loss = 0.0052\n",
            "Batch 410/455: Loss = 0.0088\n",
            "Skipping corrupted image: /content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/cardboard/cardboard 1075.jpg - cannot identify image file <_io.BufferedReader name='/content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/cardboard/cardboard 1075.jpg'>\n",
            "Batch 420/455: Loss = 0.0191\n",
            "Batch 430/455: Loss = 0.0543\n",
            "Batch 440/455: Loss = 0.0274\n",
            "Batch 450/455: Loss = 0.0180\n",
            "Training phase completed. Starting validation...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [15/25] completed.\n",
            "Train Loss: 0.0516 | Train Acc: 98.34%\n",
            "Val Loss: 0.3023 | Val Acc: 92.79%\n",
            "Precision: 92.87% | Recall: 92.72% | F1-score: 92.78%\n",
            "Checkpoint saved at /content/drive/MyDrive/Waste Classification using Transfer Learning/Saved Models/EfficientNet-B0/checkpoint_epoch_15.pth!\n",
            "\n",
            "Epoch 16/25 started...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 0/455: Loss = 0.0099\n",
            "Batch 10/455: Loss = 0.1778\n",
            "Batch 20/455: Loss = 0.2194\n",
            "Batch 30/455: Loss = 0.0110\n",
            "Batch 40/455: Loss = 0.0395\n",
            "Batch 50/455: Loss = 0.0642\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 60/455: Loss = 0.0689\n",
            "Skipping corrupted image: /content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/e-waste/e-waste 1719.jpg - cannot identify image file <_io.BufferedReader name='/content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/e-waste/e-waste 1719.jpg'>\n",
            "Batch 70/455: Loss = 0.0933\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 80/455: Loss = 0.0063\n",
            "Batch 90/455: Loss = 0.0174\n",
            "Batch 100/455: Loss = 0.0734\n",
            "Batch 110/455: Loss = 0.0026\n",
            "Batch 120/455: Loss = 0.0282\n",
            "Batch 130/455: Loss = 0.0276\n",
            "Batch 140/455: Loss = 0.0692\n",
            "Batch 150/455: Loss = 0.0069\n",
            "Batch 160/455: Loss = 0.0027\n",
            "Batch 170/455: Loss = 0.0038\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 180/455: Loss = 0.0084\n",
            "Batch 190/455: Loss = 0.0300\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 200/455: Loss = 0.0095\n",
            "Batch 210/455: Loss = 0.0369\n",
            "Batch 220/455: Loss = 0.0703\n",
            "Batch 230/455: Loss = 0.0094\n",
            "Batch 240/455: Loss = 0.0312\n",
            "Batch 250/455: Loss = 0.0652\n",
            "Batch 260/455: Loss = 0.0011\n",
            "Batch 270/455: Loss = 0.0042\n",
            "Batch 280/455: Loss = 0.0112\n",
            "Batch 290/455: Loss = 0.0175\n",
            "Skipping corrupted image: /content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/cardboard/cardboard 1075.jpg - cannot identify image file <_io.BufferedReader name='/content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/cardboard/cardboard 1075.jpg'>\n",
            "Batch 300/455: Loss = 0.0031\n",
            "Batch 310/455: Loss = 0.0070\n",
            "Batch 320/455: Loss = 0.0715\n",
            "Batch 330/455: Loss = 0.0104\n",
            "Skipping corrupted image: /content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/paper/paper 2273.jpg - cannot identify image file <_io.BufferedReader name='/content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/paper/paper 2273.jpg'>\n",
            "Batch 340/455: Loss = 0.0535\n",
            "Batch 350/455: Loss = 0.0329\n",
            "Batch 360/455: Loss = 0.0039\n",
            "Batch 370/455: Loss = 0.0381\n",
            "Batch 380/455: Loss = 0.0228\n",
            "Batch 390/455: Loss = 0.0912\n",
            "Batch 400/455: Loss = 0.0070\n",
            "Batch 410/455: Loss = 0.0281\n",
            "Batch 420/455: Loss = 0.0127\n",
            "Batch 430/455: Loss = 0.0106\n",
            "Batch 440/455: Loss = 0.0115\n",
            "Batch 450/455: Loss = 0.0600\n",
            "Training phase completed. Starting validation...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [16/25] completed.\n",
            "Train Loss: 0.0497 | Train Acc: 98.28%\n",
            "Val Loss: 0.3163 | Val Acc: 92.73%\n",
            "Precision: 92.87% | Recall: 92.42% | F1-score: 92.59%\n",
            "\n",
            "Epoch 17/25 started...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 0/455: Loss = 0.0654\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 10/455: Loss = 0.0078\n",
            "Batch 20/455: Loss = 0.0173\n",
            "Batch 30/455: Loss = 0.0048\n",
            "Batch 40/455: Loss = 0.0421\n",
            "Batch 50/455: Loss = 0.0106\n",
            "Skipping corrupted image: /content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/e-waste/e-waste 1719.jpg - cannot identify image file <_io.BufferedReader name='/content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/e-waste/e-waste 1719.jpg'>\n",
            "Batch 60/455: Loss = 0.0215\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 70/455: Loss = 0.0104\n",
            "Batch 80/455: Loss = 0.0086\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 90/455: Loss = 0.0394\n",
            "Batch 100/455: Loss = 0.0180\n",
            "Batch 110/455: Loss = 0.0329\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 120/455: Loss = 0.0862\n",
            "Batch 130/455: Loss = 0.0506\n",
            "Batch 140/455: Loss = 0.0036\n",
            "Batch 150/455: Loss = 0.0072\n",
            "Batch 160/455: Loss = 0.0446\n",
            "Batch 170/455: Loss = 0.0276\n",
            "Batch 180/455: Loss = 0.1213\n",
            "Batch 190/455: Loss = 0.0078\n",
            "Batch 200/455: Loss = 0.0853\n",
            "Batch 210/455: Loss = 0.0700\n",
            "Batch 220/455: Loss = 0.0933\n",
            "Batch 230/455: Loss = 0.0894\n",
            "Batch 240/455: Loss = 0.0098\n",
            "Batch 250/455: Loss = 0.1045\n",
            "Batch 260/455: Loss = 0.0102\n",
            "Batch 270/455: Loss = 0.0140\n",
            "Batch 280/455: Loss = 0.0158\n",
            "Batch 290/455: Loss = 0.0602\n",
            "Batch 300/455: Loss = 0.0165\n",
            "Batch 310/455: Loss = 0.0977\n",
            "Batch 320/455: Loss = 0.0133\n",
            "Skipping corrupted image: /content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/cardboard/cardboard 1075.jpg - cannot identify image file <_io.BufferedReader name='/content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/cardboard/cardboard 1075.jpg'>\n",
            "Batch 330/455: Loss = 0.1571\n",
            "Batch 340/455: Loss = 0.1006\n",
            "Batch 350/455: Loss = 0.1047\n",
            "Batch 360/455: Loss = 0.0560\n",
            "Batch 370/455: Loss = 0.0082\n",
            "Batch 380/455: Loss = 0.0960\n",
            "Batch 390/455: Loss = 0.1271\n",
            "Batch 400/455: Loss = 0.0063\n",
            "Skipping corrupted image: /content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/paper/paper 2273.jpg - cannot identify image file <_io.BufferedReader name='/content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/paper/paper 2273.jpg'>\n",
            "Batch 410/455: Loss = 0.1495\n",
            "Batch 420/455: Loss = 0.2514\n",
            "Batch 430/455: Loss = 0.0368\n",
            "Batch 440/455: Loss = 0.0565\n",
            "Batch 450/455: Loss = 0.0115\n",
            "Training phase completed. Starting validation...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [17/25] completed.\n",
            "Train Loss: 0.0484 | Train Acc: 98.43%\n",
            "Val Loss: 0.3109 | Val Acc: 93.41%\n",
            "Precision: 93.69% | Recall: 93.01% | F1-score: 93.29%\n",
            "\n",
            "Epoch 18/25 started...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 0/455: Loss = 0.0763\n",
            "Batch 10/455: Loss = 0.0116\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 20/455: Loss = 0.0272\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 30/455: Loss = 0.0101\n",
            "Batch 40/455: Loss = 0.0133\n",
            "Batch 50/455: Loss = 0.0833\n",
            "Batch 60/455: Loss = 0.0227\n",
            "Batch 70/455: Loss = 0.0095\n",
            "Batch 80/455: Loss = 0.0409\n",
            "Batch 90/455: Loss = 0.0471\n",
            "Batch 100/455: Loss = 0.0335\n",
            "Batch 110/455: Loss = 0.0050\n",
            "Batch 120/455: Loss = 0.0306\n",
            "Batch 130/455: Loss = 0.0890\n",
            "Batch 140/455: Loss = 0.0497\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 150/455: Loss = 0.0034\n",
            "Batch 160/455: Loss = 0.0149\n",
            "Batch 170/455: Loss = 0.1437\n",
            "Batch 180/455: Loss = 0.0398\n",
            "Skipping corrupted image: /content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/e-waste/e-waste 1719.jpg - cannot identify image file <_io.BufferedReader name='/content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/e-waste/e-waste 1719.jpg'>\n",
            "Batch 190/455: Loss = 0.0047\n",
            "Batch 200/455: Loss = 0.0493\n",
            "Batch 210/455: Loss = 0.1665\n",
            "Batch 220/455: Loss = 0.1914\n",
            "Batch 230/455: Loss = 0.0902\n",
            "Batch 240/455: Loss = 0.0548\n",
            "Batch 250/455: Loss = 0.0070\n",
            "Batch 260/455: Loss = 0.0759\n",
            "Batch 270/455: Loss = 0.0414\n",
            "Batch 280/455: Loss = 0.0549\n",
            "Batch 290/455: Loss = 0.0238\n",
            "Skipping corrupted image: /content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/paper/paper 2273.jpg - cannot identify image file <_io.BufferedReader name='/content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/paper/paper 2273.jpg'>\n",
            "Skipping corrupted image: /content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/cardboard/cardboard 1075.jpg - cannot identify image file <_io.BufferedReader name='/content/drive/MyDrive/Waste Classification using Transfer Learning/Dataset/cardboard/cardboard 1075.jpg'>\n",
            "Batch 300/455: Loss = 0.1833\n",
            "Batch 310/455: Loss = 0.0100\n",
            "Batch 320/455: Loss = 0.0124\n",
            "Batch 330/455: Loss = 0.2779\n",
            "Batch 340/455: Loss = 0.0431\n",
            "Batch 350/455: Loss = 0.0021\n",
            "Batch 360/455: Loss = 0.0301\n",
            "Batch 370/455: Loss = 0.0264\n",
            "Batch 380/455: Loss = 0.0548\n",
            "Batch 390/455: Loss = 0.0261\n",
            "Batch 400/455: Loss = 0.0287\n",
            "Batch 410/455: Loss = 0.0032\n",
            "Batch 420/455: Loss = 0.0032\n",
            "Batch 430/455: Loss = 0.0022\n",
            "Batch 440/455: Loss = 0.0218\n",
            "Batch 450/455: Loss = 0.0157\n",
            "Training phase completed. Starting validation...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [18/25] completed.\n",
            "Train Loss: 0.0479 | Train Acc: 98.47%\n",
            "Val Loss: 0.3127 | Val Acc: 92.61%\n",
            "Precision: 93.05% | Recall: 92.22% | F1-score: 92.55%\n",
            "Early stopping at epoch 18 due to no improvement in validation loss or accuracy.\n",
            "Training complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "# Define the folder path\n",
        "save_path = \"/content/drive/MyDrive/Waste Classification using Transfer Learning/Saved Models\"\n",
        "# os.makedirs(save_path, exist_ok=True)  # Create folder if it doesn't exist\n",
        "torch.save(model, os.path.join(save_path, \"Model_EfficientNetB0.pth\"))\n",
        "print(f\"Model saved successfully in {save_path}/Model_EfficientNetB0.pth\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-FO-gOGmfCVr",
        "outputId": "7413ad3c-fb05-4299-8aca-068d9f3c5312"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved successfully in /content/drive/MyDrive/Waste Classification using Transfer Learning/Saved Models/Model_EfficientNetB0.pth\n"
          ]
        }
      ]
    }
  ]
}